{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLH2jBYfHy2o"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Table of Contents\n",
        "1. [Dataset Overview](#dataset-overview)\n",
        "2. [Format conversion](#conversion)\n",
        "3. [Handling Missing Values](#handling-missing-values)\n",
        "4. [Feature Distributions](#feature-distributions)\n",
        "5. [Possible Biases](#possible-biases)\n",
        "6. [Correlations](#correlations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4yKkspkHy2p"
      },
      "source": [
        ". [Correlations](#correlations)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessary files\n",
        "!pip install gpxpy\n",
        "!pip install tcxreader"
      ],
      "metadata": {
        "id": "uFtVLW6cFbyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSmQCXP5Hy2q"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gpxpy\n",
        "import gpxpy.gpx\n",
        "import tcxreader\n",
        "import tcxreader.tcxreader\n",
        "import openpyxl\n",
        "import os\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "enc5tCy9E-RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or upload local dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VgUujNxzI1m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Sport1.zip -d /content"
      ],
      "metadata": {
        "id": "NoC_h4MU0WMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPhol6zGHy2r"
      },
      "source": [
        "## Dataset Overview\n",
        "\n",
        "[Provide a high-level overview of the dataset. This should include the source of the dataset, the number of samples, the number of features, and example showing the structure of the dataset.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvmAsNqmHy2r"
      },
      "outputs": [],
      "source": [
        "# Load gpx.\n",
        "gpx_path = '/content/Sport/Sport/Rider1/f1.gpx'\n",
        "with open(gpx_path) as f:\n",
        "    gpx = gpxpy.parse(f)\n",
        "\n",
        "# Convert to a dataframe one point at a time.\n",
        "points = []\n",
        "for segment in gpx.tracks[0].segments:\n",
        "    for p in segment.points:\n",
        "        points.append({\n",
        "            'time': p.time,\n",
        "            'latitude': p.latitude,\n",
        "            'longitude': p.longitude,\n",
        "            'elevation': p.elevation,\n",
        "        })\n",
        "df = pd.DataFrame.from_records(points)\n",
        "\n",
        "# Number of samples\n",
        "num_samples = df.shape[0]\n",
        "\n",
        "# Number of features\n",
        "num_features = df.shape[1]\n",
        "\n",
        "# Display these dataset characteristics\n",
        "print(f\"Number of samples: {num_samples}\")\n",
        "print(f\"Number of features: {num_features}\")\n",
        "\n",
        "# Display the first few rows of the dataframe to show the structure\n",
        "print(\"Example data:\")\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the main folder containing Rider folders\n",
        "main_path = '/content/Sport/Sport'\n",
        "\n",
        "# Iterate through each Rider folder and count the number of .gpx files\n",
        "for rider_folder in sorted(os.listdir(main_path)):\n",
        "    folder_path = os.path.join(main_path, rider_folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        gpx_files = [f for f in os.listdir(folder_path) if f.endswith('.gpx')]\n",
        "        tcx_files = [f for f in os.listdir(folder_path) if f.endswith('.tcx')]\n",
        "        print(f\"Folder '{rider_folder}' contains {len(gpx_files)} .gpx files and {len(tcx_files)} .tcx files.\")\n"
      ],
      "metadata": {
        "id": "t813gaFl5gHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion\n",
        "Convert GPX and TCX to XLS format. In order to correctly analyse all the data its format should be firstly unified."
      ],
      "metadata": {
        "id": "2bOhLPztOTOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_gpx_to_excel(gpx_file_path, output_file_path):\n",
        "  # Initialize a DataFrame to store data\n",
        "  all_data = []\n",
        "\n",
        "  # Parse the GPX file\n",
        "  with open(gpx_file_path, 'r') as gpx_file:\n",
        "      gpx = gpxpy.parse(gpx_file)\n",
        "\n",
        "  # Extract data (latitude, longitude, elevation, time, etc.)\n",
        "  for track in gpx.tracks:\n",
        "      for segment in track.segments:\n",
        "          for point in segment.points:\n",
        "              # Convert timezone-aware datetime to timezone-naive\n",
        "              naive_time = point.time.replace(tzinfo=None) if point.time else None\n",
        "\n",
        "              all_data.append({\n",
        "                  'Latitude': point.latitude,\n",
        "                  'Longitude': point.longitude,\n",
        "                  'Elevation': point.elevation,\n",
        "                  'Time': naive_time\n",
        "              })\n",
        "\n",
        "  # Convert the data into a DataFrame\n",
        "  df = pd.DataFrame(all_data)\n",
        "\n",
        "  # Write the DataFrame to an Excel file\n",
        "  df.to_excel(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "kMaGWKktMxgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TCX to XLSX\n",
        "def convert_tcx_to_excel(tcx_file_path, output_file_path):\n",
        "    \"\"\"\n",
        "    Converts a TCX file to an Excel file with trackpoint data.\n",
        "\n",
        "    Parameters:\n",
        "    - tcx_file_path: str, path to the input TCX file\n",
        "    - output_file_path: str, path to save the output Excel file\n",
        "    \"\"\"\n",
        "    # Initialize the TCX reader\n",
        "    tcx_reader = TCXReader()\n",
        "\n",
        "    # Read the TCX file\n",
        "    data: TCXExercise = tcx_reader.read(tcx_file_path)\n",
        "\n",
        "    # List to store the trackpoint data\n",
        "    trackpoint_data = []\n",
        "\n",
        "    # Loop through all trackpoints and extract relevant information\n",
        "    for trackpoint in data.trackpoints:\n",
        "        trackpoint_data.append({\n",
        "            'Time': trackpoint.time,\n",
        "            'Latitude': trackpoint.latitude,\n",
        "            'Longitude': trackpoint.longitude,\n",
        "            'Elevation': trackpoint.elevation,\n",
        "            'Distance': trackpoint.distance,\n",
        "            'Heartrate': trackpoint.hr_value,\n",
        "            'Cadence': trackpoint.cadence,\n",
        "            'Speed': trackpoint.tpx_ext['Speed']\n",
        "        })\n",
        "\n",
        "    # Convert the list of dictionaries to a pandas DataFrame\n",
        "    df = pd.DataFrame(trackpoint_data)\n",
        "\n",
        "    # Save the DataFrame to an Excel file\n",
        "    df.to_excel(output_file_path, index=False, engine='openpyxl')\n"
      ],
      "metadata": {
        "id": "RgEU9KOlQm6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directories\n",
        "sport_dir = \"/content/Sport/Sport\"\n",
        "sport_xlsx_dir = \"/content/Sport_xlsx\"\n",
        "\n",
        "# Create Sport_xlsx directory if it doesn't exist\n",
        "if not os.path.exists(sport_xlsx_dir):\n",
        "    os.makedirs(sport_xlsx_dir)\n",
        "\n",
        "# Function to convert files in a folder\n",
        "def convert_files_in_folder(rider_folder):\n",
        "    rider_xlsx_folder = os.path.join(sport_xlsx_dir, rider_folder)\n",
        "\n",
        "    # Create the rider folder in Sport_xlsx directory if it doesn't exist\n",
        "    if not os.path.exists(rider_xlsx_folder):\n",
        "        os.makedirs(rider_xlsx_folder)\n",
        "\n",
        "    rider_folder_path = os.path.join(sport_dir, rider_folder)\n",
        "\n",
        "    # Process .gpx files\n",
        "    gpx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.gpx')]\n",
        "    for gpx_file in gpx_files:\n",
        "        convert_gpx_to_excel(os.path.join(rider_folder_path, gpx_file),\n",
        "                           os.path.join(rider_xlsx_folder, gpx_file.replace('.gpx', '.xlsx')))\n",
        "\n",
        "    # Process .tcx files\n",
        "    tcx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.tcx')]\n",
        "    for tcx_file in tcx_files:\n",
        "        convert_tcx_to_excel(os.path.join(rider_folder_path, tcx_file),\n",
        "                           os.path.join(rider_xlsx_folder, tcx_file.replace('.tcx', '.xlsx')))\n"
      ],
      "metadata": {
        "id": "0IOfK69AV-J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Riders = ['Rider1', 'Rider2', 'Rider3', 'Rider4', 'Rider5', 'Rider6', 'Rider7', 'Rider8', 'Rider9']\n",
        "Riders = ['Rider2']\n",
        "for rider in Riders:\n",
        "  convert_files_in_folder(rider)"
      ],
      "metadata": {
        "id": "WTCMFC3jfFD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Sport_xlsx/Rider2.zip /content/Sport_xlsx/Rider2"
      ],
      "metadata": {
        "id": "maWIkJuUH48E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nev_B3-Hy2s"
      },
      "source": [
        "## Handling Missing Values\n",
        "\n",
        "[Identify any missing values in the dataset, and describe your approach to handle them if there are any. If there are no missing values simply indicate that there are none.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNs5dtHPHy2s"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4JnjByQHy2t"
      },
      "outputs": [],
      "source": [
        "# Handling missing values\n",
        "# Example: Replacing NaN values with the mean value of the column\n",
        "# df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Your code for handling missing values goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUpSMh_nHy2t"
      },
      "source": [
        "## Feature Distributions\n",
        "\n",
        "[Plot the distribution of various features and target variables. Comment on the skewness, outliers, or any other observations.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-BWP7n7Hy2t"
      },
      "outputs": [],
      "source": [
        "# Example: Plotting histograms of all numerical features\n",
        "df.hist(figsize=(12, 12))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nNlj2gYHy2u"
      },
      "source": [
        "## Possible Biases\n",
        "\n",
        "[Investigate the dataset for any biases that could affect the model’s performance and fairness (e.g., class imbalance, historical biases).]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmO6AleOHy2u"
      },
      "outputs": [],
      "source": [
        "# Example: Checking for class imbalance in a classification problem\n",
        "# sns.countplot(x='target_variable', data=df)\n",
        "\n",
        "# Your code to investigate possible biases goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hrCzoP5Hy2u"
      },
      "source": [
        "## Correlations\n",
        "\n",
        "[Explore correlations between features and the target variable, as well as among features themselves.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm5O5p0bHy2v"
      },
      "outputs": [],
      "source": [
        "# Example: Plotting a heatmap to show feature correlations\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}