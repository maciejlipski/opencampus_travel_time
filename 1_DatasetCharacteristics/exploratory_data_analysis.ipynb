{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLH2jBYfHy2o"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Table of Contents\n",
        "1. [Dataset Overview](#dataset-overview)\n",
        "2. [Format conversion](#conversion)\n",
        "3. [Handling Missing Values](#handling-missing-values)\n",
        "4. [Feature Distributions](#feature-distributions)\n",
        "5. [Possible Biases](#possible-biases)\n",
        "6. [Correlations](#correlations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4yKkspkHy2p"
      },
      "source": [
        ". [Correlations](#correlations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSmQCXP5Hy2q"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload local dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VgUujNxzI1m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Sport1.zip"
      ],
      "metadata": {
        "id": "NoC_h4MU0WMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPhol6zGHy2r"
      },
      "source": [
        "## Dataset Overview\n",
        "\n",
        "[Provide a high-level overview of the dataset. This should include the source of the dataset, the number of samples, the number of features, and example showing the structure of the dataset.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvmAsNqmHy2r"
      },
      "outputs": [],
      "source": [
        "#!pip install gpxpy\n",
        "\n",
        "import pandas as pd\n",
        "import gpxpy\n",
        "\n",
        "# Load gpx.\n",
        "gpx_path = '/content/Sport/Rider1/f1.gpx'\n",
        "with open(gpx_path) as f:\n",
        "    gpx = gpxpy.parse(f)\n",
        "\n",
        "# Convert to a dataframe one point at a time.\n",
        "points = []\n",
        "for segment in gpx.tracks[0].segments:\n",
        "    for p in segment.points:\n",
        "        points.append({\n",
        "            'time': p.time,\n",
        "            'latitude': p.latitude,\n",
        "            'longitude': p.longitude,\n",
        "            'elevation': p.elevation,\n",
        "        })\n",
        "df = pd.DataFrame.from_records(points)\n",
        "\n",
        "# Number of samples\n",
        "num_samples = df.shape[0]\n",
        "\n",
        "# Number of features\n",
        "num_features = df.shape[1]\n",
        "\n",
        "# Display these dataset characteristics\n",
        "print(f\"Number of samples: {num_samples}\")\n",
        "print(f\"Number of features: {num_features}\")\n",
        "\n",
        "# Display the first few rows of the dataframe to show the structure\n",
        "print(\"Example data:\")\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the main folder containing Rider folders\n",
        "main_path = '/content/Sport'\n",
        "\n",
        "# Iterate through each Rider folder and count the number of .gpx files\n",
        "for rider_folder in sorted(os.listdir(main_path)):\n",
        "    folder_path = os.path.join(main_path, rider_folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        gpx_files = [f for f in os.listdir(folder_path) if f.endswith('.gpx')]\n",
        "        tcx_files = [f for f in os.listdir(folder_path) if f.endswith('.tcx')]\n",
        "        print(f\"Folder '{rider_folder}' contains {len(gpx_files)} .gpx files and {len(tcx_files)} .tcx files.\")\n"
      ],
      "metadata": {
        "id": "t813gaFl5gHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion\n",
        "Convert GPX and TCX to XLS format. In order to correctly analyse all the data its format should be firstly unified."
      ],
      "metadata": {
        "id": "2bOhLPztOTOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPX to XLSX\n",
        "import gpxpy\n",
        "import gpxpy.gpx\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def convert_gpx_to_excel(gpx_file_path, output_file_path):\n",
        "  # Initialize a DataFrame to store data\n",
        "  all_data = []\n",
        "\n",
        "  # Parse the GPX file\n",
        "  with open(gpx_file_path, 'r') as gpx_file:\n",
        "      gpx = gpxpy.parse(gpx_file)\n",
        "\n",
        "  # Extract data (latitude, longitude, elevation, time, etc.)\n",
        "  for track in gpx.tracks:\n",
        "      for segment in track.segments:\n",
        "          for point in segment.points:\n",
        "              # Convert timezone-aware datetime to timezone-naive\n",
        "              naive_time = point.time.replace(tzinfo=None) if point.time else None\n",
        "\n",
        "              all_data.append({\n",
        "                  'Latitude': point.latitude,\n",
        "                  'Longitude': point.longitude,\n",
        "                  'Elevation': point.elevation,\n",
        "                  'Time': naive_time\n",
        "              })\n",
        "\n",
        "  # Convert the data into a DataFrame\n",
        "  df = pd.DataFrame(all_data)\n",
        "\n",
        "  # Write the DataFrame to an Excel file\n",
        "  df.to_excel(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "kMaGWKktMxgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TCX to XLSX\n",
        "import pandas as pd\n",
        "from tcxreader.tcxreader import TCXReader, TCXExercise\n",
        "\n",
        "def convert_tcx_to_excel(tcx_file_path, output_file_path):\n",
        "    \"\"\"\n",
        "    Converts a TCX file to an Excel file with trackpoint data.\n",
        "\n",
        "    Parameters:\n",
        "    - tcx_file_path: str, path to the input TCX file\n",
        "    - output_file_path: str, path to save the output Excel file\n",
        "    \"\"\"\n",
        "    # Initialize the TCX reader\n",
        "    tcx_reader = TCXReader()\n",
        "\n",
        "    # Read the TCX file\n",
        "    data: TCXExercise = tcx_reader.read(tcx_file_path)\n",
        "\n",
        "    # List to store the trackpoint data\n",
        "    trackpoint_data = []\n",
        "\n",
        "    # Loop through all trackpoints and extract relevant information\n",
        "    for trackpoint in data.trackpoints:\n",
        "        trackpoint_data.append({\n",
        "            'Time': trackpoint.time,\n",
        "            'Latitude': trackpoint.latitude,\n",
        "            'Longitude': trackpoint.longitude,\n",
        "            'Elevation': trackpoint.elevation,\n",
        "            'Distance': trackpoint.distance,\n",
        "            'Heartrate': trackpoint.hr_value,\n",
        "            'Cadence': trackpoint.cadence,\n",
        "            'Speed': trackpoint.tpx_ext['Speed']\n",
        "        })\n",
        "\n",
        "    # Convert the list of dictionaries to a pandas DataFrame\n",
        "    df = pd.DataFrame(trackpoint_data)\n",
        "\n",
        "    # Save the DataFrame to an Excel file\n",
        "    df.to_excel(output_file_path, index=False, engine='openpyxl')\n"
      ],
      "metadata": {
        "id": "RgEU9KOlQm6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the directories\n",
        "sport_dir = \"/content/Sport\"\n",
        "sport_xlsx_dir = \"/content/Sport_xlsx\"\n",
        "\n",
        "# Create Sport_xlsx directory if it doesn't exist\n",
        "if not os.path.exists(sport_xlsx_dir):\n",
        "    os.makedirs(sport_xlsx_dir)\n",
        "\n",
        "# Function to convert files in a folder\n",
        "def convert_files_in_folder(rider_folder):\n",
        "    rider_xlsx_folder = os.path.join(sport_xlsx_dir, rider_folder)\n",
        "\n",
        "    # Create the rider folder in Sport_xlsx directory if it doesn't exist\n",
        "    if not os.path.exists(rider_xlsx_folder):\n",
        "        os.makedirs(rider_xlsx_folder)\n",
        "\n",
        "    rider_folder_path = os.path.join(sport_dir, rider_folder)\n",
        "\n",
        "    # Process .gpx files\n",
        "    gpx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.gpx')]\n",
        "    for gpx_file in gpx_files:\n",
        "        convert_gpx_to_excel(os.path.join(rider_folder_path, gpx_file),\n",
        "                           os.path.join(rider_xlsx_folder, gpx_file.replace('.gpx', '.xlsx')))\n",
        "\n",
        "    # Process .tcx files\n",
        "    tcx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.tcx')]\n",
        "    for tcx_file in tcx_files:\n",
        "        convert_tcx_to_excel(os.path.join(rider_folder_path, tcx_file),\n",
        "                           os.path.join(rider_xlsx_folder, tcx_file.replace('.tcx', '.xlsx')))\n"
      ],
      "metadata": {
        "id": "0IOfK69AV-J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Riders = ['Rider1', 'Rider2', 'Rider3', 'Rider4', 'Rider5', 'Rider6', 'Rider7', 'Rider8', 'Rider9']\n",
        "for rider in Riders:\n",
        "  convert_files_in_folder(rider)"
      ],
      "metadata": {
        "id": "WTCMFC3jfFD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nev_B3-Hy2s"
      },
      "source": [
        "## Handling Missing Values\n",
        "\n",
        "[Identify any missing values in the dataset, and describe your approach to handle them if there are any. If there are no missing values simply indicate that there are none.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNs5dtHPHy2s"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4JnjByQHy2t"
      },
      "outputs": [],
      "source": [
        "# Handling missing values\n",
        "# Example: Replacing NaN values with the mean value of the column\n",
        "# df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Your code for handling missing values goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUpSMh_nHy2t"
      },
      "source": [
        "## Feature Distributions\n",
        "\n",
        "[Plot the distribution of various features and target variables. Comment on the skewness, outliers, or any other observations.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-BWP7n7Hy2t"
      },
      "outputs": [],
      "source": [
        "# Example: Plotting histograms of all numerical features\n",
        "df.hist(figsize=(12, 12))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nNlj2gYHy2u"
      },
      "source": [
        "## Possible Biases\n",
        "\n",
        "[Investigate the dataset for any biases that could affect the modelâ€™s performance and fairness (e.g., class imbalance, historical biases).]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmO6AleOHy2u"
      },
      "outputs": [],
      "source": [
        "# Example: Checking for class imbalance in a classification problem\n",
        "# sns.countplot(x='target_variable', data=df)\n",
        "\n",
        "# Your code to investigate possible biases goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hrCzoP5Hy2u"
      },
      "source": [
        "## Correlations\n",
        "\n",
        "[Explore correlations between features and the target variable, as well as among features themselves.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm5O5p0bHy2v"
      },
      "outputs": [],
      "source": [
        "# Example: Plotting a heatmap to show feature correlations\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}