{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc-lKxYs0pfx"
      },
      "source": [
        "# Baseline Model\n",
        "\n",
        "## Table of Contents\n",
        "1. [Load dataset](#load-dataset)\n",
        "2. [Feature Selection](#feature-selection)\n",
        "3. [Implementation](#implementation)\n",
        "4. [Evaluation](#evaluation)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "ibI_fHbUQjF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oto5BB4t0pf2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load dataset\n",
        "Load preprocessed dataset and print basic details."
      ],
      "metadata": {
        "id": "c8G5_jmE0tPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3MWauQ3N06KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/opencampus_all_files/combined_data_r1.csv')"
      ],
      "metadata": {
        "id": "ed71t52-HExO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfZQKrVg0pf5"
      },
      "source": [
        "## 2. Feature Selection\n",
        "\n",
        "Selected features describes terrain characteristics and cumulative statistics of current track."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOIJ9xv80pf6"
      },
      "outputs": [],
      "source": [
        "# Feature selection\n",
        "# Example: Selecting only two features for a simple baseline model\n",
        "X = df[['Elevation', 'Slope_prev', 'Slope_next', 'Angle', 'Distance', 'Cumulative_Slope']]\n",
        "y = df['Speed']\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of datasets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "6PrRXSWADx06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjECCs2Y0pf7"
      },
      "source": [
        "##  3. Implementation\n",
        "In following notebook two models were implemented:\n",
        "- Linear Regression\n",
        "- Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline model 1 - Linear Regression"
      ],
      "metadata": {
        "id": "7UMUl9g2mGQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn9eWOn10pf8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Initialize and train the model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export ml model\n",
        "import joblib\n",
        "\n",
        "# Assuming 'lr_model' is your trained Linear Regression model\n",
        "# Save the model to a file\n",
        "filename = 'linear_regression_model.joblib'\n",
        "joblib.dump(lr_model, filename)"
      ],
      "metadata": {
        "id": "2SHUojlEx6BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline model 2 - Simple Neural Network"
      ],
      "metadata": {
        "id": "-1N6WpAUmJdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # First hidden layer\n",
        "    Dense(32, activation='relu'),  # Second hidden layer\n",
        "    Dense(1)  # Output layer (no activation since we're doing regression)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
        "\n",
        "# Optionally, plot the training history (e.g., loss or MAE over epochs)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sl_RvnG1mMs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbKtVyLp0pf9"
      },
      "source": [
        "## 4. Evaluation\n",
        "\n",
        "Evaluation based on loss and MAE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess test file"
      ],
      "metadata": {
        "id": "j53HtqoPiaGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip test files\n",
        "!unzip /content/drive/MyDrive/opencampus_all_files/Rider1_test.zip -d /content"
      ],
      "metadata": {
        "id": "0PnKeCvNyUwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "df = pd.read_csv('/content/content/Rider1_test/f15.csv')\n",
        "\n",
        "# Example: Selecting only two features for a simple baseline model\n",
        "real_time = df['Time']\n",
        "X = df[['Elevation', 'Slope_prev', 'Slope_next',  'Angle', 'Distance', 'Cumulative_Slope']] # Cumulative slope\n",
        "y = df['Speed']\n"
      ],
      "metadata": {
        "id": "MclLZ8I6j9RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation 1 - Linear Regression"
      ],
      "metadata": {
        "id": "F79HFxv1c7HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the new data\n",
        "y_pred = lr_model.predict(X)\n",
        "\n",
        "# Add the predicted values as a new column 'Speed_pred' in the original DataFrame\n",
        "df['Speed_pred'] = y_pred\n",
        "\n",
        "# Optionally, check the first few rows to verify the new column is added correctly\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "-g1OnD9wkXP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MAE between df['Speed_pred'] and df['Speed']\n",
        "mae = mean_absolute_error(df['Speed'], df['Speed_pred'])\n",
        "print(f\"Mean Absolute Error: {mae}\")\n"
      ],
      "metadata": {
        "id": "eGnbQDG2WO-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation 2 - Neural Network"
      ],
      "metadata": {
        "id": "EvfWLhhPdC6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the new data using the same scaler fitted on the training data\n",
        "X_new_scaled = scaler.transform(X)\n",
        "\n",
        "# Make predictions on the new data\n",
        "y_pred = model.predict(X_new_scaled)\n",
        "\n",
        "# Add the predicted values as a new column 'Speed_pred' in the original DataFrame\n",
        "df['Speed_pred'] = y_pred\n",
        "\n",
        "# Optionally, check the first few rows to verify the new column is added correctly\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "Z-1-feh5c-Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Calculate MAE between df['Speed_pred'] and df['Speed']\n",
        "\n",
        "mae = mean_absolute_error(df['Speed'], df['Speed_pred'])\n",
        "print(f\"Mean Absolute Error: {mae}\")\n"
      ],
      "metadata": {
        "id": "BO8T_aTjXKlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "SJKt_lDbk62_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate track length in seconds"
      ],
      "metadata": {
        "id": "_MtweafKlcKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Time column\n",
        "df['pred_time'] = 0.0\n",
        "\n",
        "# Compute predicted time\n",
        "for i in range(2, len(df)):\n",
        "  if pd.notna(df.loc[i, 'Speed_pred']):\n",
        "    if df.loc[i, 'Speed_pred'] != 0:\n",
        "      df.loc[i, 'pred_time'] = df.loc[i - 1, 'pred_time'] + (df.loc[i, 'Distance'] - df.loc[i - 1, 'Distance']) / df.loc[i, 'Speed_pred']\n",
        "    else:\n",
        "      df.loc[i, 'pred_time'] = df.loc[i - 1, 'pred_time']\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "RtCMC4XYi6QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Speed', 'Speed_pred', 'Time', 'pred_time']]"
      ],
      "metadata": {
        "id": "hb-101z9p6EV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}