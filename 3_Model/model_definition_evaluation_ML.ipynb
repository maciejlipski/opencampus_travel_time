{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT7FUIMp6OyP"
      },
      "source": [
        "# Model Definition and Evaluation\n",
        "## Table of Contents\n",
        "1. [Libraries](#libraries)\n",
        "2. [Load dataset](#load-dataset)\n",
        "3. [Model configuration](#model-configuration)\n",
        "4. [Implementation](#implementation)\n",
        "5. [Evaluation](#evaluation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Libraries"
      ],
      "metadata": {
        "id": "NK1Xp7vQn3GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "zUApz9fFmWSh",
        "outputId": "4a157b22-e5ba-437f-e9a1-464db757e1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/250.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m245.8/250.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hf64Ejtw6OyQ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAjcUwdb6OyS"
      },
      "source": [
        "## 2. Load dataset\n",
        "\n",
        "Load a preprocessed data and select features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PAUqsOUCMo6w",
        "outputId": "05fa8866-3ebf-498d-ff44-72fe8f978af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7xO-oSj56OyT"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/opencampus_all_files/combined_data_r1.csv')\n",
        "\n",
        "# Feature and target variable selection\n",
        "Time_real = df['Time']\n",
        "X = df[['Elevation', 'Slope_prev', 'Slope_next',  'Angle', 'Distance', 'Cumulative_Slope']] # Cumulative slope\n",
        "y = df['Speed']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG36ZeBF6OyT"
      },
      "source": [
        "## 3. Model configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer (6 features)\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Dense(256, activation='relu'))  # Large hidden layer to capture more complex patterns\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout again after each hidden layer\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(1))  # Regression output\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Summarize the model architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "wrErJtwiNYV4",
        "outputId": "3fd6023a-ad9b-4238-802f-49637c0c38ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               896       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66945 (261.50 KB)\n",
            "Trainable params: 66945 (261.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Early Stopping: Stops training when validation loss doesn't improve.\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',       # Metric to monitor\n",
        "    patience=10,              # Number of epochs to wait for improvement\n",
        "    restore_best_weights=True # Rollback to the best model weights\n",
        ")\n",
        "\n",
        "# 2. Model Checkpoint: Saves the best model during training.\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'nn_best_model.keras',     # Filepath to save the model\n",
        "    monitor='val_loss',        # Metric to monitor\n",
        "    save_best_only=True,       # Save only the best model\n",
        "    mode='min',                # Minimize validation loss\n",
        "    verbose=1                  # Show a message when saving the model\n",
        ")\n",
        "\n",
        "# 3. Learning Rate Scheduler: Reduce learning rate when validation loss plateaus.\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',        # Metric to monitor\n",
        "    factor=0.1,                # Factor by which to reduce the learning rate\n",
        "    patience=5,                # Number of epochs to wait before reducing\n",
        "    min_lr=1e-6,               # Lower bound for learning rate\n",
        "    verbose=1                  # Show a message when reducing the learning rate\n",
        ")\n",
        "\n",
        "# Combine callbacks into a list\n",
        "callbacks = [early_stopping, model_checkpoint, reduce_lr]"
      ],
      "metadata": {
        "id": "eTAodH5MBPAT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z65lDS_96OyV"
      },
      "source": [
        "## 4. Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "b-AU9b6Icvvy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ydwm-YUa6OyV",
        "outputId": "c78c50f3-cb4e-47ec-d886-bdaae3041845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "121966/121996 [============================>.] - ETA: 0s - loss: 5.9130 - mae: 1.7073\n",
            "Epoch 1: val_loss improved from inf to 5.41552, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 5.9128 - mae: 1.7073 - val_loss: 5.4155 - val_mae: 1.6272 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "121981/121996 [============================>.] - ETA: 0s - loss: 5.4845 - mae: 1.6294\n",
            "Epoch 2: val_loss improved from 5.41552 to 5.25887, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 5.4845 - mae: 1.6294 - val_loss: 5.2589 - val_mae: 1.5903 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "121981/121996 [============================>.] - ETA: 0s - loss: 5.3520 - mae: 1.6036\n",
            "Epoch 3: val_loss improved from 5.25887 to 5.12287, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 163s 1ms/step - loss: 5.3520 - mae: 1.6036 - val_loss: 5.1229 - val_mae: 1.5572 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "121985/121996 [============================>.] - ETA: 0s - loss: 5.2739 - mae: 1.5886\n",
            "Epoch 4: val_loss improved from 5.12287 to 5.05135, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 162s 1ms/step - loss: 5.2739 - mae: 1.5886 - val_loss: 5.0513 - val_mae: 1.5446 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "121995/121996 [============================>.] - ETA: 0s - loss: 5.2133 - mae: 1.5768\n",
            "Epoch 5: val_loss did not improve from 5.05135\n",
            "121996/121996 [==============================] - 161s 1ms/step - loss: 5.2133 - mae: 1.5768 - val_loss: 5.0823 - val_mae: 1.5704 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "121988/121996 [============================>.] - ETA: 0s - loss: 5.1640 - mae: 1.5677\n",
            "Epoch 6: val_loss improved from 5.05135 to 4.93760, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 161s 1ms/step - loss: 5.1640 - mae: 1.5677 - val_loss: 4.9376 - val_mae: 1.5248 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "121972/121996 [============================>.] - ETA: 0s - loss: 5.1255 - mae: 1.5605\n",
            "Epoch 7: val_loss did not improve from 4.93760\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 5.1255 - mae: 1.5605 - val_loss: 4.9784 - val_mae: 1.5486 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "121973/121996 [============================>.] - ETA: 0s - loss: 5.0921 - mae: 1.5544\n",
            "Epoch 8: val_loss improved from 4.93760 to 4.92749, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 5.0921 - mae: 1.5544 - val_loss: 4.9275 - val_mae: 1.5255 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "121973/121996 [============================>.] - ETA: 0s - loss: 5.0652 - mae: 1.5500\n",
            "Epoch 9: val_loss did not improve from 4.92749\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 5.0652 - mae: 1.5500 - val_loss: 5.0228 - val_mae: 1.5910 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "121983/121996 [============================>.] - ETA: 0s - loss: 5.0433 - mae: 1.5464\n",
            "Epoch 10: val_loss improved from 4.92749 to 4.81400, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 5.0433 - mae: 1.5464 - val_loss: 4.8140 - val_mae: 1.4999 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "121990/121996 [============================>.] - ETA: 0s - loss: 5.0215 - mae: 1.5422\n",
            "Epoch 11: val_loss improved from 4.81400 to 4.80157, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 5.0215 - mae: 1.5422 - val_loss: 4.8016 - val_mae: 1.4966 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "121969/121996 [============================>.] - ETA: 0s - loss: 5.0024 - mae: 1.5392\n",
            "Epoch 12: val_loss did not improve from 4.80157\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 5.0025 - mae: 1.5392 - val_loss: 4.8114 - val_mae: 1.4968 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "121993/121996 [============================>.] - ETA: 0s - loss: 4.9865 - mae: 1.5362\n",
            "Epoch 13: val_loss improved from 4.80157 to 4.74975, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.9865 - mae: 1.5362 - val_loss: 4.7497 - val_mae: 1.4708 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "121979/121996 [============================>.] - ETA: 0s - loss: 4.9743 - mae: 1.5341\n",
            "Epoch 14: val_loss did not improve from 4.74975\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.9743 - mae: 1.5341 - val_loss: 4.7741 - val_mae: 1.5081 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "121973/121996 [============================>.] - ETA: 0s - loss: 4.9606 - mae: 1.5316\n",
            "Epoch 15: val_loss improved from 4.74975 to 4.73930, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.9606 - mae: 1.5316 - val_loss: 4.7393 - val_mae: 1.4964 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "121992/121996 [============================>.] - ETA: 0s - loss: 4.9465 - mae: 1.5292\n",
            "Epoch 16: val_loss improved from 4.73930 to 4.73784, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 167s 1ms/step - loss: 4.9466 - mae: 1.5292 - val_loss: 4.7378 - val_mae: 1.4882 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "121970/121996 [============================>.] - ETA: 0s - loss: 4.9377 - mae: 1.5282\n",
            "Epoch 17: val_loss improved from 4.73784 to 4.72056, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.9376 - mae: 1.5282 - val_loss: 4.7206 - val_mae: 1.5013 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "121985/121996 [============================>.] - ETA: 0s - loss: 4.9257 - mae: 1.5261\n",
            "Epoch 18: val_loss did not improve from 4.72056\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.9256 - mae: 1.5261 - val_loss: 4.7325 - val_mae: 1.5085 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "121982/121996 [============================>.] - ETA: 0s - loss: 4.9152 - mae: 1.5243\n",
            "Epoch 19: val_loss did not improve from 4.72056\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.9152 - mae: 1.5243 - val_loss: 4.7615 - val_mae: 1.5238 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "121970/121996 [============================>.] - ETA: 0s - loss: 4.9062 - mae: 1.5230\n",
            "Epoch 20: val_loss improved from 4.72056 to 4.69278, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 4.9062 - mae: 1.5231 - val_loss: 4.6928 - val_mae: 1.4921 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "121985/121996 [============================>.] - ETA: 0s - loss: 4.8987 - mae: 1.5214\n",
            "Epoch 21: val_loss did not improve from 4.69278\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 4.8987 - mae: 1.5214 - val_loss: 4.8201 - val_mae: 1.5129 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "121980/121996 [============================>.] - ETA: 0s - loss: 4.8924 - mae: 1.5202\n",
            "Epoch 22: val_loss improved from 4.69278 to 4.66425, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 163s 1ms/step - loss: 4.8923 - mae: 1.5202 - val_loss: 4.6642 - val_mae: 1.4829 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "121996/121996 [==============================] - ETA: 0s - loss: 4.8845 - mae: 1.5186\n",
            "Epoch 23: val_loss did not improve from 4.66425\n",
            "121996/121996 [==============================] - 162s 1ms/step - loss: 4.8845 - mae: 1.5186 - val_loss: 4.7251 - val_mae: 1.5124 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "121980/121996 [============================>.] - ETA: 0s - loss: 4.8785 - mae: 1.5178\n",
            "Epoch 24: val_loss did not improve from 4.66425\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 4.8785 - mae: 1.5178 - val_loss: 4.7414 - val_mae: 1.5084 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "121963/121996 [============================>.] - ETA: 0s - loss: 4.8723 - mae: 1.5167\n",
            "Epoch 25: val_loss did not improve from 4.66425\n",
            "121996/121996 [==============================] - 163s 1ms/step - loss: 4.8722 - mae: 1.5167 - val_loss: 4.7382 - val_mae: 1.5049 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "121993/121996 [============================>.] - ETA: 0s - loss: 4.8635 - mae: 1.5151\n",
            "Epoch 26: val_loss did not improve from 4.66425\n",
            "121996/121996 [==============================] - 163s 1ms/step - loss: 4.8635 - mae: 1.5151 - val_loss: 4.6886 - val_mae: 1.4939 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "121973/121996 [============================>.] - ETA: 0s - loss: 4.8562 - mae: 1.5135\n",
            "Epoch 27: val_loss did not improve from 4.66425\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.8573 - mae: 1.5135 - val_loss: 4.7234 - val_mae: 1.5013 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "121977/121996 [============================>.] - ETA: 0s - loss: 4.6252 - mae: 1.4604\n",
            "Epoch 28: val_loss improved from 4.66425 to 4.46129, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 4.6252 - mae: 1.4604 - val_loss: 4.4613 - val_mae: 1.4508 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "121971/121996 [============================>.] - ETA: 0s - loss: 4.5936 - mae: 1.4542\n",
            "Epoch 29: val_loss improved from 4.46129 to 4.41451, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 163s 1ms/step - loss: 4.5938 - mae: 1.4542 - val_loss: 4.4145 - val_mae: 1.4349 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "121982/121996 [============================>.] - ETA: 0s - loss: 4.5863 - mae: 1.4524\n",
            "Epoch 30: val_loss improved from 4.41451 to 4.41285, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5864 - mae: 1.4524 - val_loss: 4.4129 - val_mae: 1.4373 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "121962/121996 [============================>.] - ETA: 0s - loss: 4.5752 - mae: 1.4505\n",
            "Epoch 31: val_loss improved from 4.41285 to 4.40519, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 4.5753 - mae: 1.4505 - val_loss: 4.4052 - val_mae: 1.4322 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "121996/121996 [==============================] - ETA: 0s - loss: 4.5685 - mae: 1.4490\n",
            "Epoch 32: val_loss did not improve from 4.40519\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 4.5685 - mae: 1.4490 - val_loss: 4.4234 - val_mae: 1.4451 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "121985/121996 [============================>.] - ETA: 0s - loss: 4.5650 - mae: 1.4485\n",
            "Epoch 33: val_loss did not improve from 4.40519\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5650 - mae: 1.4485 - val_loss: 4.4154 - val_mae: 1.4371 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "121965/121996 [============================>.] - ETA: 0s - loss: 4.5605 - mae: 1.4473\n",
            "Epoch 34: val_loss did not improve from 4.40519\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5606 - mae: 1.4473 - val_loss: 4.4088 - val_mae: 1.4401 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "121989/121996 [============================>.] - ETA: 0s - loss: 4.5593 - mae: 1.4468\n",
            "Epoch 35: val_loss did not improve from 4.40519\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5592 - mae: 1.4468 - val_loss: 4.4153 - val_mae: 1.4421 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "121979/121996 [============================>.] - ETA: 0s - loss: 4.5559 - mae: 1.4459\n",
            "Epoch 36: val_loss improved from 4.40519 to 4.37860, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5558 - mae: 1.4460 - val_loss: 4.3786 - val_mae: 1.4266 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "121972/121996 [============================>.] - ETA: 0s - loss: 4.5515 - mae: 1.4457\n",
            "Epoch 37: val_loss improved from 4.37860 to 4.37401, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5516 - mae: 1.4457 - val_loss: 4.3740 - val_mae: 1.4244 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "121963/121996 [============================>.] - ETA: 0s - loss: 4.5488 - mae: 1.4449\n",
            "Epoch 38: val_loss did not improve from 4.37401\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5489 - mae: 1.4449 - val_loss: 4.3889 - val_mae: 1.4336 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "121987/121996 [============================>.] - ETA: 0s - loss: 4.5451 - mae: 1.4445\n",
            "Epoch 39: val_loss did not improve from 4.37401\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5450 - mae: 1.4444 - val_loss: 4.3846 - val_mae: 1.4268 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "121966/121996 [============================>.] - ETA: 0s - loss: 4.5404 - mae: 1.4438\n",
            "Epoch 40: val_loss did not improve from 4.37401\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5403 - mae: 1.4437 - val_loss: 4.4018 - val_mae: 1.4417 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "121959/121996 [============================>.] - ETA: 0s - loss: 4.5394 - mae: 1.4433\n",
            "Epoch 41: val_loss did not improve from 4.37401\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5395 - mae: 1.4433 - val_loss: 4.4379 - val_mae: 1.4626 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "121982/121996 [============================>.] - ETA: 0s - loss: 4.5356 - mae: 1.4426\n",
            "Epoch 42: val_loss did not improve from 4.37401\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "121996/121996 [==============================] - 164s 1ms/step - loss: 4.5356 - mae: 1.4426 - val_loss: 4.3811 - val_mae: 1.4333 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "121981/121996 [============================>.] - ETA: 0s - loss: 4.5150 - mae: 1.4376\n",
            "Epoch 43: val_loss improved from 4.37401 to 4.36142, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5154 - mae: 1.4376 - val_loss: 4.3614 - val_mae: 1.4271 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "121956/121996 [============================>.] - ETA: 0s - loss: 4.5081 - mae: 1.4365\n",
            "Epoch 44: val_loss improved from 4.36142 to 4.36061, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5084 - mae: 1.4365 - val_loss: 4.3606 - val_mae: 1.4267 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "121984/121996 [============================>.] - ETA: 0s - loss: 4.5090 - mae: 1.4367\n",
            "Epoch 45: val_loss improved from 4.36061 to 4.36002, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5089 - mae: 1.4367 - val_loss: 4.3600 - val_mae: 1.4262 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "121962/121996 [============================>.] - ETA: 0s - loss: 4.5066 - mae: 1.4360\n",
            "Epoch 46: val_loss improved from 4.36002 to 4.35663, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5066 - mae: 1.4360 - val_loss: 4.3566 - val_mae: 1.4255 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "121991/121996 [============================>.] - ETA: 0s - loss: 4.5101 - mae: 1.4368\n",
            "Epoch 47: val_loss improved from 4.35663 to 4.34975, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5101 - mae: 1.4368 - val_loss: 4.3498 - val_mae: 1.4223 - lr: 1.0000e-05\n",
            "Epoch 48/100\n",
            "121989/121996 [============================>.] - ETA: 0s - loss: 4.5063 - mae: 1.4359\n",
            "Epoch 48: val_loss improved from 4.34975 to 4.34899, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5063 - mae: 1.4359 - val_loss: 4.3490 - val_mae: 1.4228 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "121970/121996 [============================>.] - ETA: 0s - loss: 4.5049 - mae: 1.4361\n",
            "Epoch 49: val_loss did not improve from 4.34899\n",
            "121996/121996 [==============================] - 167s 1ms/step - loss: 4.5048 - mae: 1.4361 - val_loss: 4.3581 - val_mae: 1.4263 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "121995/121996 [============================>.] - ETA: 0s - loss: 4.5071 - mae: 1.4355\n",
            "Epoch 50: val_loss did not improve from 4.34899\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5071 - mae: 1.4355 - val_loss: 4.3536 - val_mae: 1.4251 - lr: 1.0000e-05\n",
            "Epoch 51/100\n",
            "121996/121996 [==============================] - ETA: 0s - loss: 4.5058 - mae: 1.4360\n",
            "Epoch 51: val_loss did not improve from 4.34899\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5058 - mae: 1.4360 - val_loss: 4.3618 - val_mae: 1.4309 - lr: 1.0000e-05\n",
            "Epoch 52/100\n",
            "121986/121996 [============================>.] - ETA: 0s - loss: 4.5017 - mae: 1.4350\n",
            "Epoch 52: val_loss did not improve from 4.34899\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5017 - mae: 1.4350 - val_loss: 4.3545 - val_mae: 1.4262 - lr: 1.0000e-05\n",
            "Epoch 53/100\n",
            "121988/121996 [============================>.] - ETA: 0s - loss: 4.5040 - mae: 1.4351\n",
            "Epoch 53: val_loss did not improve from 4.34899\n",
            "\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5041 - mae: 1.4351 - val_loss: 4.3492 - val_mae: 1.4239 - lr: 1.0000e-05\n",
            "Epoch 54/100\n",
            "121960/121996 [============================>.] - ETA: 0s - loss: 4.5017 - mae: 1.4351\n",
            "Epoch 54: val_loss did not improve from 4.34899\n",
            "121996/121996 [==============================] - 168s 1ms/step - loss: 4.5019 - mae: 1.4351 - val_loss: 4.3496 - val_mae: 1.4241 - lr: 1.0000e-06\n",
            "Epoch 55/100\n",
            "121993/121996 [============================>.] - ETA: 0s - loss: 4.5011 - mae: 1.4348\n",
            "Epoch 55: val_loss did not improve from 4.34899\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5011 - mae: 1.4348 - val_loss: 4.3513 - val_mae: 1.4249 - lr: 1.0000e-06\n",
            "Epoch 56/100\n",
            "121988/121996 [============================>.] - ETA: 0s - loss: 4.5010 - mae: 1.4349\n",
            "Epoch 56: val_loss did not improve from 4.34899\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5010 - mae: 1.4349 - val_loss: 4.3497 - val_mae: 1.4233 - lr: 1.0000e-06\n",
            "Epoch 57/100\n",
            "121980/121996 [============================>.] - ETA: 0s - loss: 4.4976 - mae: 1.4342\n",
            "Epoch 57: val_loss improved from 4.34899 to 4.34855, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.4976 - mae: 1.4342 - val_loss: 4.3486 - val_mae: 1.4236 - lr: 1.0000e-06\n",
            "Epoch 58/100\n",
            "121987/121996 [============================>.] - ETA: 0s - loss: 4.4995 - mae: 1.4349\n",
            "Epoch 58: val_loss did not improve from 4.34855\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.4994 - mae: 1.4349 - val_loss: 4.3492 - val_mae: 1.4238 - lr: 1.0000e-06\n",
            "Epoch 59/100\n",
            "121966/121996 [============================>.] - ETA: 0s - loss: 4.5034 - mae: 1.4352\n",
            "Epoch 59: val_loss improved from 4.34855 to 4.34658, saving model to nn_best_model.keras\n",
            "121996/121996 [==============================] - 167s 1ms/step - loss: 4.5034 - mae: 1.4352 - val_loss: 4.3466 - val_mae: 1.4221 - lr: 1.0000e-06\n",
            "Epoch 60/100\n",
            "121957/121996 [============================>.] - ETA: 0s - loss: 4.4979 - mae: 1.4345\n",
            "Epoch 60: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.4979 - mae: 1.4345 - val_loss: 4.3518 - val_mae: 1.4252 - lr: 1.0000e-06\n",
            "Epoch 61/100\n",
            "121988/121996 [============================>.] - ETA: 0s - loss: 4.4993 - mae: 1.4348\n",
            "Epoch 61: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.4993 - mae: 1.4348 - val_loss: 4.3474 - val_mae: 1.4227 - lr: 1.0000e-06\n",
            "Epoch 62/100\n",
            "121974/121996 [============================>.] - ETA: 0s - loss: 4.5004 - mae: 1.4349\n",
            "Epoch 62: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5003 - mae: 1.4349 - val_loss: 4.3505 - val_mae: 1.4247 - lr: 1.0000e-06\n",
            "Epoch 63/100\n",
            "121987/121996 [============================>.] - ETA: 0s - loss: 4.5005 - mae: 1.4348\n",
            "Epoch 63: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 167s 1ms/step - loss: 4.5005 - mae: 1.4348 - val_loss: 4.3490 - val_mae: 1.4239 - lr: 1.0000e-06\n",
            "Epoch 64/100\n",
            "121971/121996 [============================>.] - ETA: 0s - loss: 4.5012 - mae: 1.4349\n",
            "Epoch 64: val_loss did not improve from 4.34658\n",
            "\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "121996/121996 [==============================] - 168s 1ms/step - loss: 4.5011 - mae: 1.4349 - val_loss: 4.3542 - val_mae: 1.4268 - lr: 1.0000e-06\n",
            "Epoch 65/100\n",
            "121962/121996 [============================>.] - ETA: 0s - loss: 4.4983 - mae: 1.4344\n",
            "Epoch 65: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 167s 1ms/step - loss: 4.4984 - mae: 1.4344 - val_loss: 4.3491 - val_mae: 1.4240 - lr: 1.0000e-06\n",
            "Epoch 66/100\n",
            "121962/121996 [============================>.] - ETA: 0s - loss: 4.5016 - mae: 1.4350\n",
            "Epoch 66: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 165s 1ms/step - loss: 4.5014 - mae: 1.4350 - val_loss: 4.3511 - val_mae: 1.4251 - lr: 1.0000e-06\n",
            "Epoch 67/100\n",
            "121964/121996 [============================>.] - ETA: 0s - loss: 4.5009 - mae: 1.4349\n",
            "Epoch 67: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5009 - mae: 1.4349 - val_loss: 4.3492 - val_mae: 1.4236 - lr: 1.0000e-06\n",
            "Epoch 68/100\n",
            "121988/121996 [============================>.] - ETA: 0s - loss: 4.5006 - mae: 1.4348\n",
            "Epoch 68: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.5006 - mae: 1.4348 - val_loss: 4.3490 - val_mae: 1.4241 - lr: 1.0000e-06\n",
            "Epoch 69/100\n",
            "121974/121996 [============================>.] - ETA: 0s - loss: 4.4999 - mae: 1.4349\n",
            "Epoch 69: val_loss did not improve from 4.34658\n",
            "121996/121996 [==============================] - 166s 1ms/step - loss: 4.4999 - mae: 1.4349 - val_loss: 4.3493 - val_mae: 1.4242 - lr: 1.0000e-06\n",
            "13556/13556 [==============================] - 11s 777us/step - loss: 4.3466 - mae: 1.4221\n",
            "Test Loss: 4.34657621383667, Test MAE: 1.4221044778823853\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train the model with callbacks\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    callbacks=callbacks       # Pass callbacks to the fit method\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
        "\n",
        "# Optionally, plot the training history (e.g., loss or MAE over epochs)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brH6Z8VK6OyW"
      },
      "source": [
        "## 5. Evaluation\n",
        "\n",
        "Comparison between linear and neural network model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load test files"
      ],
      "metadata": {
        "id": "j53HtqoPiaGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip test files\n",
        "!unzip /content/drive/MyDrive/opencampus_all_files/Rider1_test.zip -d /content"
      ],
      "metadata": {
        "id": "0PnKeCvNyUwr",
        "outputId": "3e1ac856-5fcb-4727-86a5-1f47a2eaeb8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/opencampus_all_files/Rider1_test.zip\n",
            "   creating: /content/content/Rider1_test/\n",
            "  inflating: /content/content/Rider1_test/f729.csv  \n",
            "  inflating: /content/content/Rider1_test/f573.csv  \n",
            "  inflating: /content/content/Rider1_test/f274.csv  \n",
            "  inflating: /content/content/Rider1_test/f15.csv  \n",
            "  inflating: /content/content/Rider1_test/f70.csv  \n",
            "  inflating: /content/content/Rider1_test/f358.csv  \n",
            "  inflating: /content/content/Rider1_test/f196.csv  \n",
            "  inflating: /content/content/Rider1_test/f737.csv  \n",
            "  inflating: /content/content/Rider1_test/f540.csv  \n",
            "  inflating: /content/content/Rider1_test/f434.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation 1 - Linear Regression"
      ],
      "metadata": {
        "id": "F79HFxv1c7HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load linear model\n",
        "lr_model = joblib.load('/content/drive/MyDrive/opencampus_all_files/models/r1_init_lr_model.joblib')"
      ],
      "metadata": {
        "id": "A8LXO0L1zxI5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder containing the files\n",
        "input_folder_path = '/content/content/Rider1_test/'\n",
        "output_folder_path = '/content/content/Rider1_test_LR/'\n",
        "\n",
        "# Create output_folder_path\n",
        "if not os.path.exists(output_folder_path):\n",
        "    os.makedirs(output_folder_path)\n",
        "\n",
        "# List all CSV files in the folder\n",
        "csv_files = [f for f in os.listdir(input_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Iterate through each file in the folder\n",
        "for file in csv_files:\n",
        "    file_path = os.path.join(input_folder_path, file)\n",
        "\n",
        "    # Read test file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Feature selection\n",
        "    real_time = df['Time']\n",
        "    X = df[['Elevation', 'Slope_prev', 'Slope_next', 'Angle', 'Distance', 'Cumulative_Slope']]\n",
        "    y = df['Speed']\n",
        "\n",
        "    # Make predictions on the new data\n",
        "    y_pred = lr_model.predict(X)\n",
        "\n",
        "    # Add the predicted values as a new column 'Speed_pred' in the original DataFrame\n",
        "    df['Speed_pred'] = y_pred\n",
        "\n",
        "    # Calculate MAE between df['Speed_pred'] and df['Speed']\n",
        "    mae = mean_absolute_error(df['Speed'], df['Speed_pred'])\n",
        "    print(f\"File: {file} | Mean Absolute Error: {mae}\")\n",
        "\n",
        "    # Initialize Time column\n",
        "    df['Time_pred'] = float(df['Time'].iloc[0])\n",
        "\n",
        "    # Compute predicted time\n",
        "    for i in range(2, len(df)):\n",
        "        if df.loc[i, 'Speed_pred'] < 0:\n",
        "            df.loc[i, 'Speed_pred'] = 0\n",
        "        if pd.notna(df.loc[i, 'Speed_pred']):\n",
        "            if df.loc[i, 'Speed_pred'] != 0:\n",
        "                df.loc[i, 'Time_pred'] = (\n",
        "                    df.loc[i - 1, 'Time_pred'] +\n",
        "                    (df.loc[i, 'Distance'] - df.loc[i - 1, 'Distance']) / df.loc[i, 'Speed_pred']\n",
        "                )\n",
        "            else:\n",
        "                df.loc[i, 'Time_pred'] = df.loc[i - 1, 'Time_pred']\n",
        "\n",
        "    # Save the processed DataFrame to a new file (optional)\n",
        "    output_file_path = os.path.join(output_folder_path, f\"lr_{file}\")\n",
        "    df.to_csv(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "eGnbQDG2WO-_",
        "outputId": "fd2eafc3-3230-4345-97ea-35b1ed93b676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: f729.csv | Mean Absolute Error: 3.7590308974823663\n",
            "File: f573.csv | Mean Absolute Error: 3.023838732251371\n",
            "File: f274.csv | Mean Absolute Error: 2.990506993991007\n",
            "File: f15.csv | Mean Absolute Error: 4.369134090674801\n",
            "File: f70.csv | Mean Absolute Error: 4.585313688421683\n",
            "File: f358.csv | Mean Absolute Error: 2.2341906067906083\n",
            "File: f196.csv | Mean Absolute Error: 2.018804913641264\n",
            "File: f737.csv | Mean Absolute Error: 1.9240215480755247\n",
            "File: f540.csv | Mean Absolute Error: 3.665805771576365\n",
            "File: f434.csv | Mean Absolute Error: 2.437380576433266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation 2 - Neural Network"
      ],
      "metadata": {
        "id": "EvfWLhhPdC6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load linear model\n",
        "nn_model = tf.keras.models.load_model('/content/drive/MyDrive/opencampus_all_files/models/r1_best_nn_model.keras')"
      ],
      "metadata": {
        "id": "Z-1-feh5c-Vb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder containing the files\n",
        "input_folder_path = '/content/content/Rider1_test/'\n",
        "output_folder_path = '/content/content/Rider1_test_NN/'\n",
        "\n",
        "# Create output_folder_path\n",
        "if not os.path.exists(output_folder_path):\n",
        "    os.makedirs(output_folder_path)\n",
        "\n",
        "# List all CSV files in the folder\n",
        "csv_files = [f for f in os.listdir(input_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Iterate through each file in the folder\n",
        "for file in csv_files:\n",
        "    file_path = os.path.join(input_folder_path, file)\n",
        "\n",
        "    # Read test file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Feature selection\n",
        "    real_time = df['Time']\n",
        "    X = df[['Elevation', 'Slope_prev', 'Slope_next', 'Angle', 'Distance', 'Cumulative_Slope']]\n",
        "    y = df['Speed']\n",
        "\n",
        "    # Make predictions on the new data\n",
        "    X_new_scaled = scaler.transform(X)\n",
        "    y_pred = nn_model.predict(X_new_scaled)\n",
        "\n",
        "    # Add the predicted values as a new column 'Speed_pred' in the original DataFrame\n",
        "    df['Speed_pred'] = y_pred\n",
        "\n",
        "    # Calculate MAE between df['Speed_pred'] and df['Speed']\n",
        "    mae = mean_absolute_error(df['Speed'], df['Speed_pred'])\n",
        "    print(f\"File: {file} | Mean Absolute Error: {mae}\")\n",
        "\n",
        "    # Initialize Time column\n",
        "    df['Time_pred'] = float(df['Time'].iloc[0])\n",
        "\n",
        "    # Compute predicted time\n",
        "    for i in range(2, len(df)):\n",
        "        if df.loc[i, 'Speed_pred'] < 0:\n",
        "            df.loc[i, 'Speed_pred'] = 0\n",
        "        if pd.notna(df.loc[i, 'Speed_pred']):\n",
        "            if df.loc[i, 'Speed_pred'] != 0:\n",
        "                df.loc[i, 'Time_pred'] = (\n",
        "                    df.loc[i - 1, 'Time_pred'] +\n",
        "                    (df.loc[i, 'Distance'] - df.loc[i - 1, 'Distance']) / df.loc[i, 'Speed_pred']\n",
        "                )\n",
        "            else:\n",
        "                df.loc[i, 'Time_pred'] = df.loc[i - 1, 'Time_pred']\n",
        "\n",
        "    # Save the processed DataFrame to a new file (optional)\n",
        "    output_file_path = os.path.join(output_folder_path, f\"nn_{file}\")\n",
        "    df.to_csv(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "BO8T_aTjXKlK",
        "outputId": "ab710ea1-9336-4192-b8f0-39d35a284f57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 0s 733us/step\n",
            "File: f729.csv | Mean Absolute Error: 1.9640048754557657\n",
            "27/27 [==============================] - 0s 748us/step\n",
            "File: f573.csv | Mean Absolute Error: 2.33422941750691\n",
            "137/137 [==============================] - 0s 743us/step\n",
            "File: f274.csv | Mean Absolute Error: 2.231364139427358\n",
            "45/45 [==============================] - 0s 712us/step\n",
            "File: f15.csv | Mean Absolute Error: 2.9045932467843705\n",
            "59/59 [==============================] - 0s 717us/step\n",
            "File: f70.csv | Mean Absolute Error: 2.2105558923946944\n",
            "239/239 [==============================] - 0s 715us/step\n",
            "File: f358.csv | Mean Absolute Error: 1.2407014579102085\n",
            "72/72 [==============================] - 0s 767us/step\n",
            "File: f196.csv | Mean Absolute Error: 1.6722027774969703\n",
            "61/61 [==============================] - 0s 794us/step\n",
            "File: f737.csv | Mean Absolute Error: 1.86628655022557\n",
            "86/86 [==============================] - 0s 798us/step\n",
            "File: f540.csv | Mean Absolute Error: 1.4723059086137145\n",
            "428/428 [==============================] - 0s 691us/step\n",
            "File: f434.csv | Mean Absolute Error: 2.0102556045539592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation summary"
      ],
      "metadata": {
        "id": "_MtweafKlcKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for processed files\n",
        "output_folder_path = '/content/content/Rider1_test_LR/'\n",
        "summary_lr = []\n",
        "processed_files = [f for f in os.listdir(output_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "for file in processed_files:\n",
        "    file_path = os.path.join(output_folder_path, file)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Extract the last value of 'Time' and 'Time_pred'\n",
        "    last_time = df['Time'].iloc[-1]\n",
        "    last_time_pred = df['Time_pred'].iloc[-1]\n",
        "\n",
        "    # Calculate percentage difference\n",
        "    percentage_diff = ((last_time_pred - last_time) / last_time) * 100 if last_time != 0 else None\n",
        "\n",
        "    # Append to summary\n",
        "    summary_lr.append({\n",
        "        'file': file,\n",
        "        'last_time': last_time,\n",
        "        'last_time_pred': last_time_pred,\n",
        "        'percentage_diff': percentage_diff\n",
        "    })"
      ],
      "metadata": {
        "id": "RtCMC4XYi6QO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for processed files\n",
        "output_folder_path = '/content/content/Rider1_test_NN/'\n",
        "summary_nn = []\n",
        "processed_files = [f for f in os.listdir(output_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "for file in processed_files:\n",
        "    file_path = os.path.join(output_folder_path, file)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Extract the last value of 'Time' and 'Time_pred'\n",
        "    last_time = df['Time'].iloc[-1]\n",
        "    last_time_pred = df['Time_pred'].iloc[-1]\n",
        "\n",
        "    # Calculate percentage difference\n",
        "    percentage_diff = ((last_time_pred - last_time) / last_time) * 100 if last_time != 0 else None\n",
        "\n",
        "    # Append to summary\n",
        "    summary_nn.append({\n",
        "        'file': file,\n",
        "        'last_time': last_time,\n",
        "        'last_time_pred': last_time_pred,\n",
        "        'percentage_diff': percentage_diff\n",
        "    })"
      ],
      "metadata": {
        "id": "L_Q6xesa8UbX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print summary\n",
        "summary_lr_df = pd.DataFrame(summary_lr).sort_values(by=['file'])\n",
        "print(summary_lr_df)\n",
        "print(f\"Absolute percentage difference in LR model: {summary_lr_df['percentage_diff'].abs().mean()}\\n\")\n",
        "\n",
        "summary_nn_df = pd.DataFrame(summary_nn).sort_values(by=['file'])\n",
        "print(summary_nn_df)\n",
        "print(f\"Absolute percentage difference in NN model: {summary_nn_df['percentage_diff'].abs().mean()}\")"
      ],
      "metadata": {
        "id": "WU5ltW-L8RfJ",
        "outputId": "85f80eb6-3e81-41a2-a3b6-a730072d9d26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          file  last_time  last_time_pred  percentage_diff\n",
            "2   lr_f15.csv       3468     4891.403847        41.043940\n",
            "4  lr_f196.csv       6416     6652.877966         3.691988\n",
            "5  lr_f274.csv       4918     5689.160556        15.680369\n",
            "9  lr_f358.csv      13207    13835.069860         4.755583\n",
            "1  lr_f434.csv      18232    15334.294793       -15.893513\n",
            "3  lr_f540.csv       5786     4061.035690       -29.812726\n",
            "0  lr_f573.csv       1322     1214.018365        -8.168051\n",
            "6   lr_f70.csv       4001     1309.591636       -67.268392\n",
            "8  lr_f729.csv       3734     1937.769505       -48.104727\n",
            "7  lr_f737.csv       1979     2126.388820         7.447641\n",
            "Absolute percentage difference in LR model: 24.186693000542977\n",
            "\n",
            "          file  last_time  last_time_pred  percentage_diff\n",
            "1   nn_f15.csv       3468     4036.899984        16.404267\n",
            "0  nn_f196.csv       6416     6497.516846         1.270524\n",
            "7  nn_f274.csv       4918     5065.703712         3.003329\n",
            "5  nn_f358.csv      13207    13440.777126         1.770100\n",
            "2  nn_f434.csv      18232    14662.411623       -19.578699\n",
            "3  nn_f540.csv       5786     4420.920939       -23.592794\n",
            "4  nn_f573.csv       1322     1653.663119        25.087982\n",
            "6   nn_f70.csv       4001     2035.312305       -49.129910\n",
            "8  nn_f729.csv       3734     2784.268013       -25.434708\n",
            "9  nn_f737.csv       1979     1814.050083        -8.335013\n",
            "Absolute percentage difference in NN model: 17.36073262240657\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}