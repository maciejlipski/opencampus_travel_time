{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT7FUIMp6OyP"
      },
      "source": [
        "# Model Definition and Evaluation\n",
        "## Table of Contents\n",
        "1. [Libraries](#libraries)\n",
        "2. [Load dataset](#load-dataset)\n",
        "3. [Model configuration](#model-configuration)\n",
        "4. [Implementation](#implementation)\n",
        "5. [Evaluation](#evaluation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Libraries"
      ],
      "metadata": {
        "id": "NK1Xp7vQn3GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "zUApz9fFmWSh",
        "outputId": "21647b8c-8f0b-456f-ebb6-5303a4f3241d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/250.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/250.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hf64Ejtw6OyQ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAjcUwdb6OyS"
      },
      "source": [
        "## 2. Load dataset\n",
        "\n",
        "Load a preprocessed data and select features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PAUqsOUCMo6w",
        "outputId": "d4521a8a-b1b3-4baa-cde3-de1aef66c731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7xO-oSj56OyT"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/opencampus_all_files/combined_data_r1.csv')\n",
        "\n",
        "# Feature and target variable selection\n",
        "Time_real = df['Time']\n",
        "X = df[['Elevation', 'Slope_prev', 'Slope_next',  'Angle', 'Distance', 'Cumulative_Slope']] # Cumulative slope\n",
        "y = df['Speed']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG36ZeBF6OyT"
      },
      "source": [
        "## 3. Model configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer (6 features)\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Dense(256, activation='relu'))  # Large hidden layer to capture more complex patterns\n",
        "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout again after each hidden layer\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(1))  # Regression output\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Summarize the model architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "wrErJtwiNYV4",
        "outputId": "866fc038-a980-46df-cf5f-ab4c0ad941b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 128)               896       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66945 (261.50 KB)\n",
            "Trainable params: 66945 (261.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Early Stopping: Stops training when validation loss doesn't improve.\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',       # Metric to monitor\n",
        "    patience=10,              # Number of epochs to wait for improvement\n",
        "    restore_best_weights=True # Rollback to the best model weights\n",
        ")\n",
        "\n",
        "# 2. Model Checkpoint: Saves the best model during training.\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'nn_best_model.keras',     # Filepath to save the model\n",
        "    monitor='val_loss',        # Metric to monitor\n",
        "    save_best_only=True,       # Save only the best model\n",
        "    mode='min',                # Minimize validation loss\n",
        "    verbose=1                  # Show a message when saving the model\n",
        ")\n",
        "\n",
        "# 3. Learning Rate Scheduler: Reduce learning rate when validation loss plateaus.\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',        # Metric to monitor\n",
        "    factor=0.1,                # Factor by which to reduce the learning rate\n",
        "    patience=5,                # Number of epochs to wait before reducing\n",
        "    min_lr=1e-6,               # Lower bound for learning rate\n",
        "    verbose=1                  # Show a message when reducing the learning rate\n",
        ")\n",
        "\n",
        "# Combine callbacks into a list\n",
        "callbacks = [early_stopping, model_checkpoint, reduce_lr]"
      ],
      "metadata": {
        "id": "eTAodH5MBPAT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z65lDS_96OyV"
      },
      "source": [
        "## 4. Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "b-AU9b6Icvvy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ydwm-YUa6OyV",
        "outputId": "65bb960b-a9cf-407f-e174-27e3727c7828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "122050/122083 [============================>.] - ETA: 0s - loss: 5.6689 - mae: 1.7005\n",
            "Epoch 1: val_loss improved from inf to 5.19802, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 179s 1ms/step - loss: 5.6689 - mae: 1.7005 - val_loss: 5.1980 - val_mae: 1.6102 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "122074/122083 [============================>.] - ETA: 0s - loss: 5.2295 - mae: 1.6187\n",
            "Epoch 2: val_loss improved from 5.19802 to 4.99002, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 180s 1ms/step - loss: 5.2295 - mae: 1.6187 - val_loss: 4.9900 - val_mae: 1.5765 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "122051/122083 [============================>.] - ETA: 0s - loss: 5.0956 - mae: 1.5928\n",
            "Epoch 3: val_loss improved from 4.99002 to 4.83945, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 5.0955 - mae: 1.5928 - val_loss: 4.8395 - val_mae: 1.5368 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "122083/122083 [==============================] - ETA: 0s - loss: 5.0135 - mae: 1.5762\n",
            "Epoch 4: val_loss improved from 4.83945 to 4.80912, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 5.0135 - mae: 1.5762 - val_loss: 4.8091 - val_mae: 1.5403 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "122072/122083 [============================>.] - ETA: 0s - loss: 4.9554 - mae: 1.5649\n",
            "Epoch 5: val_loss improved from 4.80912 to 4.73796, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 174s 1ms/step - loss: 4.9554 - mae: 1.5649 - val_loss: 4.7380 - val_mae: 1.5130 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "122082/122083 [============================>.] - ETA: 0s - loss: 4.9102 - mae: 1.5561\n",
            "Epoch 6: val_loss improved from 4.73796 to 4.73776, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.9102 - mae: 1.5561 - val_loss: 4.7378 - val_mae: 1.5459 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "122049/122083 [============================>.] - ETA: 0s - loss: 4.8738 - mae: 1.5491\n",
            "Epoch 7: val_loss improved from 4.73776 to 4.67993, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.8737 - mae: 1.5491 - val_loss: 4.6799 - val_mae: 1.5239 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "122065/122083 [============================>.] - ETA: 0s - loss: 4.8442 - mae: 1.5439\n",
            "Epoch 8: val_loss did not improve from 4.67993\n",
            "122083/122083 [==============================] - 176s 1ms/step - loss: 4.8442 - mae: 1.5439 - val_loss: 4.7190 - val_mae: 1.5350 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "122060/122083 [============================>.] - ETA: 0s - loss: 4.8175 - mae: 1.5395\n",
            "Epoch 9: val_loss improved from 4.67993 to 4.65029, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.8176 - mae: 1.5395 - val_loss: 4.6503 - val_mae: 1.5169 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "122057/122083 [============================>.] - ETA: 0s - loss: 4.7974 - mae: 1.5359\n",
            "Epoch 10: val_loss improved from 4.65029 to 4.58489, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.7974 - mae: 1.5359 - val_loss: 4.5849 - val_mae: 1.5019 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "122055/122083 [============================>.] - ETA: 0s - loss: 4.7773 - mae: 1.5321\n",
            "Epoch 11: val_loss improved from 4.58489 to 4.55709, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.7773 - mae: 1.5321 - val_loss: 4.5571 - val_mae: 1.4905 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "122065/122083 [============================>.] - ETA: 0s - loss: 4.7603 - mae: 1.5287\n",
            "Epoch 12: val_loss did not improve from 4.55709\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.7604 - mae: 1.5287 - val_loss: 4.6858 - val_mae: 1.5554 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "122081/122083 [============================>.] - ETA: 0s - loss: 4.7452 - mae: 1.5262\n",
            "Epoch 13: val_loss did not improve from 4.55709\n",
            "122083/122083 [==============================] - 174s 1ms/step - loss: 4.7452 - mae: 1.5262 - val_loss: 4.7188 - val_mae: 1.5236 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "122071/122083 [============================>.] - ETA: 0s - loss: 4.7321 - mae: 1.5240\n",
            "Epoch 14: val_loss improved from 4.55709 to 4.50192, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.7322 - mae: 1.5240 - val_loss: 4.5019 - val_mae: 1.4679 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "122067/122083 [============================>.] - ETA: 0s - loss: 4.7160 - mae: 1.5209\n",
            "Epoch 15: val_loss improved from 4.50192 to 4.48807, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.7159 - mae: 1.5209 - val_loss: 4.4881 - val_mae: 1.4857 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "122064/122083 [============================>.] - ETA: 0s - loss: 4.7029 - mae: 1.5182\n",
            "Epoch 16: val_loss did not improve from 4.48807\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.7030 - mae: 1.5182 - val_loss: 4.5170 - val_mae: 1.4945 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "122058/122083 [============================>.] - ETA: 0s - loss: 4.6916 - mae: 1.5161\n",
            "Epoch 17: val_loss did not improve from 4.48807\n",
            "122083/122083 [==============================] - 177s 1ms/step - loss: 4.6916 - mae: 1.5161 - val_loss: 4.5353 - val_mae: 1.5073 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "122077/122083 [============================>.] - ETA: 0s - loss: 4.6829 - mae: 1.5150\n",
            "Epoch 18: val_loss improved from 4.48807 to 4.42068, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.6829 - mae: 1.5150 - val_loss: 4.4207 - val_mae: 1.4476 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "122079/122083 [============================>.] - ETA: 0s - loss: 4.6701 - mae: 1.5125\n",
            "Epoch 19: val_loss did not improve from 4.42068\n",
            "122083/122083 [==============================] - 174s 1ms/step - loss: 4.6701 - mae: 1.5125 - val_loss: 4.5229 - val_mae: 1.4939 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "122074/122083 [============================>.] - ETA: 0s - loss: 4.6592 - mae: 1.5109\n",
            "Epoch 20: val_loss did not improve from 4.42068\n",
            "122083/122083 [==============================] - 175s 1ms/step - loss: 4.6592 - mae: 1.5109 - val_loss: 4.4787 - val_mae: 1.4879 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "122073/122083 [============================>.] - ETA: 0s - loss: 4.6513 - mae: 1.5093\n",
            "Epoch 21: val_loss did not improve from 4.42068\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.6513 - mae: 1.5093 - val_loss: 4.4501 - val_mae: 1.4835 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "122077/122083 [============================>.] - ETA: 0s - loss: 4.6433 - mae: 1.5077\n",
            "Epoch 22: val_loss did not improve from 4.42068\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.6433 - mae: 1.5077 - val_loss: 4.4780 - val_mae: 1.4937 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "122050/122083 [============================>.] - ETA: 0s - loss: 4.6376 - mae: 1.5064\n",
            "Epoch 23: val_loss improved from 4.42068 to 4.40108, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.6376 - mae: 1.5064 - val_loss: 4.4011 - val_mae: 1.4459 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "122058/122083 [============================>.] - ETA: 0s - loss: 4.6292 - mae: 1.5051\n",
            "Epoch 24: val_loss did not improve from 4.40108\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.6292 - mae: 1.5051 - val_loss: 4.4368 - val_mae: 1.4573 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "122072/122083 [============================>.] - ETA: 0s - loss: 4.6222 - mae: 1.5038\n",
            "Epoch 25: val_loss did not improve from 4.40108\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.6222 - mae: 1.5038 - val_loss: 4.4096 - val_mae: 1.4460 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "122064/122083 [============================>.] - ETA: 0s - loss: 4.6206 - mae: 1.5037\n",
            "Epoch 26: val_loss did not improve from 4.40108\n",
            "122083/122083 [==============================] - 174s 1ms/step - loss: 4.6206 - mae: 1.5037 - val_loss: 4.4066 - val_mae: 1.4676 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "122074/122083 [============================>.] - ETA: 0s - loss: 4.6137 - mae: 1.5026\n",
            "Epoch 27: val_loss did not improve from 4.40108\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.6137 - mae: 1.5026 - val_loss: 4.4717 - val_mae: 1.4974 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "122063/122083 [============================>.] - ETA: 0s - loss: 4.6067 - mae: 1.5014\n",
            "Epoch 28: val_loss improved from 4.40108 to 4.35367, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 173s 1ms/step - loss: 4.6067 - mae: 1.5014 - val_loss: 4.3537 - val_mae: 1.4396 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "122068/122083 [============================>.] - ETA: 0s - loss: 4.6013 - mae: 1.5004\n",
            "Epoch 29: val_loss did not improve from 4.35367\n",
            "122083/122083 [==============================] - 169s 1ms/step - loss: 4.6012 - mae: 1.5004 - val_loss: 4.3664 - val_mae: 1.4442 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "122082/122083 [============================>.] - ETA: 0s - loss: 4.5960 - mae: 1.4995\n",
            "Epoch 30: val_loss did not improve from 4.35367\n",
            "122083/122083 [==============================] - 170s 1ms/step - loss: 4.5960 - mae: 1.4995 - val_loss: 4.4925 - val_mae: 1.5101 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "122057/122083 [============================>.] - ETA: 0s - loss: 4.5913 - mae: 1.4988\n",
            "Epoch 31: val_loss did not improve from 4.35367\n",
            "122083/122083 [==============================] - 169s 1ms/step - loss: 4.5914 - mae: 1.4988 - val_loss: 4.3796 - val_mae: 1.4511 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "122068/122083 [============================>.] - ETA: 0s - loss: 4.5869 - mae: 1.4983\n",
            "Epoch 32: val_loss did not improve from 4.35367\n",
            "122083/122083 [==============================] - 171s 1ms/step - loss: 4.5869 - mae: 1.4983 - val_loss: 4.3690 - val_mae: 1.4411 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "122074/122083 [============================>.] - ETA: 0s - loss: 4.5826 - mae: 1.4966\n",
            "Epoch 33: val_loss improved from 4.35367 to 4.35200, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 171s 1ms/step - loss: 4.5826 - mae: 1.4966 - val_loss: 4.3520 - val_mae: 1.4420 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "122060/122083 [============================>.] - ETA: 0s - loss: 4.5775 - mae: 1.4962\n",
            "Epoch 34: val_loss did not improve from 4.35200\n",
            "122083/122083 [==============================] - 171s 1ms/step - loss: 4.5775 - mae: 1.4962 - val_loss: 4.4451 - val_mae: 1.4992 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "122080/122083 [============================>.] - ETA: 0s - loss: 4.5727 - mae: 1.4955\n",
            "Epoch 35: val_loss did not improve from 4.35200\n",
            "122083/122083 [==============================] - 171s 1ms/step - loss: 4.5727 - mae: 1.4955 - val_loss: 4.3911 - val_mae: 1.4662 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "122074/122083 [============================>.] - ETA: 0s - loss: 4.5687 - mae: 1.4955\n",
            "Epoch 36: val_loss did not improve from 4.35200\n",
            "122083/122083 [==============================] - 170s 1ms/step - loss: 4.5687 - mae: 1.4955 - val_loss: 4.4191 - val_mae: 1.4914 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "122064/122083 [============================>.] - ETA: 0s - loss: 4.5642 - mae: 1.4943\n",
            "Epoch 37: val_loss did not improve from 4.35200\n",
            "122083/122083 [==============================] - 169s 1ms/step - loss: 4.5642 - mae: 1.4943 - val_loss: 4.3643 - val_mae: 1.4710 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "122082/122083 [============================>.] - ETA: 0s - loss: 4.5611 - mae: 1.4937\n",
            "Epoch 38: val_loss did not improve from 4.35200\n",
            "\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "122083/122083 [==============================] - 171s 1ms/step - loss: 4.5611 - mae: 1.4937 - val_loss: 4.3808 - val_mae: 1.4737 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "122064/122083 [============================>.] - ETA: 0s - loss: 4.3313 - mae: 1.4408\n",
            "Epoch 39: val_loss improved from 4.35200 to 4.12704, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 171s 1ms/step - loss: 4.3313 - mae: 1.4408 - val_loss: 4.1270 - val_mae: 1.4043 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "122055/122083 [============================>.] - ETA: 0s - loss: 4.2990 - mae: 1.4340\n",
            "Epoch 40: val_loss did not improve from 4.12704\n",
            "122083/122083 [==============================] - 167s 1ms/step - loss: 4.2990 - mae: 1.4340 - val_loss: 4.1406 - val_mae: 1.4154 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "122063/122083 [============================>.] - ETA: 0s - loss: 4.2889 - mae: 1.4317\n",
            "Epoch 41: val_loss improved from 4.12704 to 4.11110, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 166s 1ms/step - loss: 4.2889 - mae: 1.4317 - val_loss: 4.1111 - val_mae: 1.4001 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "122072/122083 [============================>.] - ETA: 0s - loss: 4.2801 - mae: 1.4300\n",
            "Epoch 42: val_loss did not improve from 4.11110\n",
            "122083/122083 [==============================] - 166s 1ms/step - loss: 4.2801 - mae: 1.4300 - val_loss: 4.1154 - val_mae: 1.4057 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "122055/122083 [============================>.] - ETA: 0s - loss: 4.2752 - mae: 1.4288\n",
            "Epoch 43: val_loss improved from 4.11110 to 4.09257, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 167s 1ms/step - loss: 4.2751 - mae: 1.4288 - val_loss: 4.0926 - val_mae: 1.3981 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "122067/122083 [============================>.] - ETA: 0s - loss: 4.2720 - mae: 1.4283\n",
            "Epoch 44: val_loss did not improve from 4.09257\n",
            "122083/122083 [==============================] - 167s 1ms/step - loss: 4.2719 - mae: 1.4283 - val_loss: 4.1068 - val_mae: 1.3956 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "122070/122083 [============================>.] - ETA: 0s - loss: 4.2670 - mae: 1.4273\n",
            "Epoch 45: val_loss improved from 4.09257 to 4.08686, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 166s 1ms/step - loss: 4.2670 - mae: 1.4273 - val_loss: 4.0869 - val_mae: 1.3948 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "122083/122083 [==============================] - ETA: 0s - loss: 4.2627 - mae: 1.4269\n",
            "Epoch 46: val_loss did not improve from 4.08686\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2627 - mae: 1.4269 - val_loss: 4.0952 - val_mae: 1.4024 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "122057/122083 [============================>.] - ETA: 0s - loss: 4.2621 - mae: 1.4262\n",
            "Epoch 47: val_loss improved from 4.08686 to 4.07667, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 161s 1ms/step - loss: 4.2622 - mae: 1.4262 - val_loss: 4.0767 - val_mae: 1.3923 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "122077/122083 [============================>.] - ETA: 0s - loss: 4.2578 - mae: 1.4255\n",
            "Epoch 48: val_loss did not improve from 4.07667\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2578 - mae: 1.4255 - val_loss: 4.0810 - val_mae: 1.3987 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "122069/122083 [============================>.] - ETA: 0s - loss: 4.2554 - mae: 1.4250\n",
            "Epoch 49: val_loss did not improve from 4.07667\n",
            "122083/122083 [==============================] - 162s 1ms/step - loss: 4.2554 - mae: 1.4250 - val_loss: 4.0917 - val_mae: 1.3917 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "122076/122083 [============================>.] - ETA: 0s - loss: 4.2520 - mae: 1.4242\n",
            "Epoch 50: val_loss did not improve from 4.07667\n",
            "122083/122083 [==============================] - 162s 1ms/step - loss: 4.2520 - mae: 1.4242 - val_loss: 4.0992 - val_mae: 1.4062 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "122050/122083 [============================>.] - ETA: 0s - loss: 4.2492 - mae: 1.4241\n",
            "Epoch 51: val_loss did not improve from 4.07667\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2493 - mae: 1.4241 - val_loss: 4.0798 - val_mae: 1.3999 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "122050/122083 [============================>.] - ETA: 0s - loss: 4.2499 - mae: 1.4238\n",
            "Epoch 52: val_loss did not improve from 4.07667\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2500 - mae: 1.4238 - val_loss: 4.0899 - val_mae: 1.4047 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "122075/122083 [============================>.] - ETA: 0s - loss: 4.2246 - mae: 1.4188\n",
            "Epoch 53: val_loss improved from 4.07667 to 4.05738, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2246 - mae: 1.4188 - val_loss: 4.0574 - val_mae: 1.3926 - lr: 1.0000e-05\n",
            "Epoch 54/100\n",
            "122046/122083 [============================>.] - ETA: 0s - loss: 4.2193 - mae: 1.4174\n",
            "Epoch 54: val_loss did not improve from 4.05738\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2195 - mae: 1.4174 - val_loss: 4.0660 - val_mae: 1.3959 - lr: 1.0000e-05\n",
            "Epoch 55/100\n",
            "122048/122083 [============================>.] - ETA: 0s - loss: 4.2194 - mae: 1.4174\n",
            "Epoch 55: val_loss improved from 4.05738 to 4.05274, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2195 - mae: 1.4174 - val_loss: 4.0527 - val_mae: 1.3901 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "122047/122083 [============================>.] - ETA: 0s - loss: 4.2197 - mae: 1.4173\n",
            "Epoch 56: val_loss did not improve from 4.05274\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2196 - mae: 1.4173 - val_loss: 4.0576 - val_mae: 1.3929 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "122072/122083 [============================>.] - ETA: 0s - loss: 4.2187 - mae: 1.4168\n",
            "Epoch 57: val_loss did not improve from 4.05274\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2186 - mae: 1.4168 - val_loss: 4.0603 - val_mae: 1.3939 - lr: 1.0000e-05\n",
            "Epoch 58/100\n",
            "122058/122083 [============================>.] - ETA: 0s - loss: 4.2204 - mae: 1.4171\n",
            "Epoch 58: val_loss did not improve from 4.05274\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2204 - mae: 1.4171 - val_loss: 4.0558 - val_mae: 1.3920 - lr: 1.0000e-05\n",
            "Epoch 59/100\n",
            "122056/122083 [============================>.] - ETA: 0s - loss: 4.2184 - mae: 1.4168\n",
            "Epoch 59: val_loss did not improve from 4.05274\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2185 - mae: 1.4168 - val_loss: 4.0542 - val_mae: 1.3895 - lr: 1.0000e-05\n",
            "Epoch 60/100\n",
            "122076/122083 [============================>.] - ETA: 0s - loss: 4.2187 - mae: 1.4169\n",
            "Epoch 60: val_loss improved from 4.05274 to 4.05029, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2187 - mae: 1.4169 - val_loss: 4.0503 - val_mae: 1.3886 - lr: 1.0000e-05\n",
            "Epoch 61/100\n",
            "122077/122083 [============================>.] - ETA: 0s - loss: 4.2169 - mae: 1.4166\n",
            "Epoch 61: val_loss improved from 4.05029 to 4.05008, saving model to nn_best_model.keras\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2169 - mae: 1.4166 - val_loss: 4.0501 - val_mae: 1.3908 - lr: 1.0000e-05\n",
            "Epoch 62/100\n",
            "122072/122083 [============================>.] - ETA: 0s - loss: 4.2181 - mae: 1.4169\n",
            "Epoch 62: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2180 - mae: 1.4169 - val_loss: 4.0580 - val_mae: 1.3929 - lr: 1.0000e-05\n",
            "Epoch 63/100\n",
            "122056/122083 [============================>.] - ETA: 0s - loss: 4.2180 - mae: 1.4166\n",
            "Epoch 63: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2181 - mae: 1.4166 - val_loss: 4.0564 - val_mae: 1.3923 - lr: 1.0000e-05\n",
            "Epoch 64/100\n",
            "122058/122083 [============================>.] - ETA: 0s - loss: 4.2142 - mae: 1.4162\n",
            "Epoch 64: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 163s 1ms/step - loss: 4.2143 - mae: 1.4162 - val_loss: 4.0536 - val_mae: 1.3920 - lr: 1.0000e-05\n",
            "Epoch 65/100\n",
            "122076/122083 [============================>.] - ETA: 0s - loss: 4.2135 - mae: 1.4161\n",
            "Epoch 65: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 162s 1ms/step - loss: 4.2135 - mae: 1.4161 - val_loss: 4.0561 - val_mae: 1.3924 - lr: 1.0000e-05\n",
            "Epoch 66/100\n",
            "122056/122083 [============================>.] - ETA: 0s - loss: 4.2159 - mae: 1.4160\n",
            "Epoch 66: val_loss did not improve from 4.05008\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2159 - mae: 1.4160 - val_loss: 4.0516 - val_mae: 1.3895 - lr: 1.0000e-05\n",
            "Epoch 67/100\n",
            "122080/122083 [============================>.] - ETA: 0s - loss: 4.2134 - mae: 1.4158\n",
            "Epoch 67: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2134 - mae: 1.4158 - val_loss: 4.0508 - val_mae: 1.3906 - lr: 1.0000e-06\n",
            "Epoch 68/100\n",
            "122060/122083 [============================>.] - ETA: 0s - loss: 4.2140 - mae: 1.4160\n",
            "Epoch 68: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 164s 1ms/step - loss: 4.2141 - mae: 1.4160 - val_loss: 4.0533 - val_mae: 1.3916 - lr: 1.0000e-06\n",
            "Epoch 69/100\n",
            "122078/122083 [============================>.] - ETA: 0s - loss: 4.2122 - mae: 1.4156\n",
            "Epoch 69: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 168s 1ms/step - loss: 4.2122 - mae: 1.4156 - val_loss: 4.0515 - val_mae: 1.3906 - lr: 1.0000e-06\n",
            "Epoch 70/100\n",
            "122056/122083 [============================>.] - ETA: 0s - loss: 4.2117 - mae: 1.4157\n",
            "Epoch 70: val_loss did not improve from 4.05008\n",
            "122083/122083 [==============================] - 166s 1ms/step - loss: 4.2118 - mae: 1.4157 - val_loss: 4.0509 - val_mae: 1.3907 - lr: 1.0000e-06\n",
            "Epoch 71/100\n",
            "122050/122083 [============================>.] - ETA: 0s - loss: 4.2115 - mae: 1.4156\n",
            "Epoch 71: val_loss did not improve from 4.05008\n",
            "\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "122083/122083 [==============================] - 167s 1ms/step - loss: 4.2115 - mae: 1.4156 - val_loss: 4.0524 - val_mae: 1.3914 - lr: 1.0000e-06\n",
            "13565/13565 [==============================] - 10s 765us/step - loss: 4.0501 - mae: 1.3908\n",
            "Test Loss: 4.050083637237549, Test MAE: 1.390834093093872\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c6706e7c-dfbd-49fd-9450-890bc4bae1c9\", \"nn_best_model.keras\", 838271)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train the model with callbacks\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    callbacks=callbacks       # Pass callbacks to the fit method\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
        "\n",
        "# Optionally, plot the training history (e.g., loss or MAE over epochs)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Download calculated model on local drive\n",
        "from google.colab import files\n",
        "file_path = '/content/nn_best_model.keras'  # Full path to the file\n",
        "files.download(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brH6Z8VK6OyW"
      },
      "source": [
        "## 5. Evaluation\n",
        "\n",
        "Comparison between linear and neural network model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load test files"
      ],
      "metadata": {
        "id": "j53HtqoPiaGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip test files\n",
        "!unzip /content/drive/MyDrive/opencampus_all_files/Rider1_test.zip -d /content"
      ],
      "metadata": {
        "id": "0PnKeCvNyUwr",
        "outputId": "8fb2d126-55da-4bfc-f119-de04810bdd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/opencampus_all_files/Rider1_test.zip\n",
            "   creating: /content/content/Rider1_test/\n",
            "  inflating: /content/content/Rider1_test/f234.csv  \n",
            "  inflating: /content/content/Rider1_test/f114.csv  \n",
            "  inflating: /content/content/Rider1_test/f123.csv  \n",
            "  inflating: /content/content/Rider1_test/f673.csv  \n",
            "  inflating: /content/content/Rider1_test/f80.csv  \n",
            "  inflating: /content/content/Rider1_test/f660.csv  \n",
            "  inflating: /content/content/Rider1_test/f562.csv  \n",
            "  inflating: /content/content/Rider1_test/f593.csv  \n",
            "  inflating: /content/content/Rider1_test/f196.csv  \n",
            "  inflating: /content/content/Rider1_test/f139.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation 1 - Linear Regression"
      ],
      "metadata": {
        "id": "F79HFxv1c7HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load linear model\n",
        "lr_model = joblib.load('/content/drive/MyDrive/opencampus_all_files/models/r1_init_lr_model.joblib')"
      ],
      "metadata": {
        "id": "A8LXO0L1zxI5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder containing the files\n",
        "input_folder_path = '/content/content/Rider1_test/'\n",
        "output_folder_path = '/content/content/Rider1_test_LR/'\n",
        "\n",
        "# Create output_folder_path\n",
        "if not os.path.exists(output_folder_path):\n",
        "    os.makedirs(output_folder_path)\n",
        "\n",
        "# List all CSV files in the folder\n",
        "csv_files = [f for f in os.listdir(input_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Iterate through each file in the folder\n",
        "for file in csv_files:\n",
        "    file_path = os.path.join(input_folder_path, file)\n",
        "\n",
        "    # Read test file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Feature selection\n",
        "    real_time = df['Time']\n",
        "    X = df[['Elevation', 'Slope_prev', 'Slope_next', 'Angle', 'Distance', 'Cumulative_Slope']]\n",
        "    y = df['Speed']\n",
        "\n",
        "    # Make predictions on the new data\n",
        "    y_pred = lr_model.predict(X)\n",
        "\n",
        "    # Add the predicted values as a new column 'Speed_pred' in the original DataFrame\n",
        "    df['Speed_pred'] = y_pred\n",
        "\n",
        "    # Calculate MAE between df['Speed_pred'] and df['Speed']\n",
        "    mae = mean_absolute_error(df['Speed'], df['Speed_pred'])\n",
        "    print(f\"File: {file} | Mean Absolute Error: {mae}\")\n",
        "\n",
        "    # Initialize Time column\n",
        "    df['Time_pred'] = float(df['Time'].iloc[0])\n",
        "\n",
        "    # Compute predicted time\n",
        "    for i in range(2, len(df)):\n",
        "        if df.loc[i, 'Speed_pred'] < 0:\n",
        "            df.loc[i, 'Speed_pred'] = 0\n",
        "        if pd.notna(df.loc[i, 'Speed_pred']):\n",
        "            if df.loc[i, 'Speed_pred'] != 0:\n",
        "                df.loc[i, 'Time_pred'] = (\n",
        "                    df.loc[i - 1, 'Time_pred'] +\n",
        "                    (df.loc[i, 'Distance'] - df.loc[i - 1, 'Distance']) / df.loc[i, 'Speed_pred']\n",
        "                )\n",
        "            else:\n",
        "                df.loc[i, 'Time_pred'] = df.loc[i - 1, 'Time_pred']\n",
        "\n",
        "    # Save the processed DataFrame to a new file (optional)\n",
        "    output_file_path = os.path.join(output_folder_path, f\"lr_{file}\")\n",
        "    df.to_csv(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "eGnbQDG2WO-_",
        "outputId": "8e6cfc3e-546e-49f9-f776-05b0e562cd3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: f234.csv | Mean Absolute Error: 2.980792894230048\n",
            "File: f114.csv | Mean Absolute Error: 2.1758634010648676\n",
            "File: f123.csv | Mean Absolute Error: 2.1395880332919908\n",
            "File: f673.csv | Mean Absolute Error: 2.7583182845739076\n",
            "File: f80.csv | Mean Absolute Error: 3.1165551353569567\n",
            "File: f660.csv | Mean Absolute Error: 2.3357295365921154\n",
            "File: f562.csv | Mean Absolute Error: 1.1986977908986125\n",
            "File: f593.csv | Mean Absolute Error: 2.0479725876983568\n",
            "File: f196.csv | Mean Absolute Error: 2.018120244616942\n",
            "File: f139.csv | Mean Absolute Error: 2.5149619944373445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation 2 - Neural Network"
      ],
      "metadata": {
        "id": "EvfWLhhPdC6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load neural network model\n",
        "nn_model = tf.keras.models.load_model(\"/content/drive/MyDrive/opencampus_all_files/models/r1_mse_nn_model.keras\")"
      ],
      "metadata": {
        "id": "Z-1-feh5c-Vb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder containing the files\n",
        "input_folder_path = '/content/content/Rider1_test/'\n",
        "output_folder_path = '/content/content/Rider1_test_NN/'\n",
        "\n",
        "# Create output_folder_path\n",
        "if not os.path.exists(output_folder_path):\n",
        "    os.makedirs(output_folder_path)\n",
        "\n",
        "# List all CSV files in the folder\n",
        "csv_files = [f for f in os.listdir(input_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Iterate through each file in the folder\n",
        "for file in csv_files:\n",
        "    file_path = os.path.join(input_folder_path, file)\n",
        "\n",
        "    # Read test file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Feature selection\n",
        "    real_time = df['Time']\n",
        "    X = df[['Elevation', 'Slope_prev', 'Slope_next', 'Angle', 'Distance', 'Cumulative_Slope']]\n",
        "    y = df['Speed']\n",
        "\n",
        "    # Make predictions on the new data\n",
        "    X_new_scaled = scaler.transform(X)\n",
        "    y_pred = nn_model.predict(X_new_scaled)\n",
        "\n",
        "    # Add the predicted values as a new column 'Speed_pred' in the original DataFrame\n",
        "    df['Speed_pred'] = y_pred\n",
        "\n",
        "    # Calculate MAE between df['Speed_pred'] and df['Speed']\n",
        "    mae = mean_absolute_error(df['Speed'], df['Speed_pred'])\n",
        "    print(f\"File: {file} | Mean Absolute Error: {mae}\")\n",
        "\n",
        "    # Initialize Time column\n",
        "    df['Time_pred'] = float(df['Time'].iloc[0])\n",
        "\n",
        "    # Compute predicted time\n",
        "    for i in range(2, len(df)):\n",
        "        if df.loc[i, 'Speed_pred'] < 0:\n",
        "            df.loc[i, 'Speed_pred'] = 0\n",
        "        if pd.notna(df.loc[i, 'Speed_pred']):\n",
        "            if df.loc[i, 'Speed_pred'] != 0:\n",
        "                df.loc[i, 'Time_pred'] = (\n",
        "                    df.loc[i - 1, 'Time_pred'] +\n",
        "                    (df.loc[i, 'Distance'] - df.loc[i - 1, 'Distance']) / df.loc[i, 'Speed_pred']\n",
        "                )\n",
        "            else:\n",
        "                df.loc[i, 'Time_pred'] = df.loc[i - 1, 'Time_pred']\n",
        "\n",
        "    # Save the processed DataFrame to a new file (optional)\n",
        "    output_file_path = os.path.join(output_folder_path, f\"nn_{file}\")\n",
        "    df.to_csv(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "BO8T_aTjXKlK",
        "outputId": "7bb1b01a-ec2a-4021-be23-97039b167f11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196/196 [==============================] - 0s 706us/step\n",
            "File: f234.csv | Mean Absolute Error: 2.2359945545324096\n",
            "126/126 [==============================] - 0s 681us/step\n",
            "File: f114.csv | Mean Absolute Error: 1.2125920878913399\n",
            "45/45 [==============================] - 0s 728us/step\n",
            "File: f123.csv | Mean Absolute Error: 1.721405879037368\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "File: f673.csv | Mean Absolute Error: 0.9237244192731451\n",
            "150/150 [==============================] - 0s 666us/step\n",
            "File: f80.csv | Mean Absolute Error: 2.0681988571727468\n",
            "183/183 [==============================] - 0s 672us/step\n",
            "File: f660.csv | Mean Absolute Error: 2.282606358061368\n",
            "19/19 [==============================] - 0s 721us/step\n",
            "File: f562.csv | Mean Absolute Error: 2.2316132898434957\n",
            "101/101 [==============================] - 0s 657us/step\n",
            "File: f593.csv | Mean Absolute Error: 0.9770658289576473\n",
            "72/72 [==============================] - 0s 634us/step\n",
            "File: f196.csv | Mean Absolute Error: 1.650549752535734\n",
            "242/242 [==============================] - 0s 777us/step\n",
            "File: f139.csv | Mean Absolute Error: 0.9931574232339063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation summary"
      ],
      "metadata": {
        "id": "_MtweafKlcKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for processed files\n",
        "output_folder_path = '/content/content/Rider1_test_LR/'\n",
        "summary_lr = []\n",
        "processed_files = [f for f in os.listdir(output_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "for file in processed_files:\n",
        "    file_path = os.path.join(output_folder_path, file)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Extract the last value of 'Time' and 'Time_pred'\n",
        "    last_time = df['Time'].iloc[-1]\n",
        "    last_time_pred = df['Time_pred'].iloc[-1]\n",
        "\n",
        "    # Calculate percentage difference\n",
        "    percentage_diff = ((last_time_pred - last_time) / last_time) * 100 if last_time != 0 else None\n",
        "\n",
        "    # Append to summary\n",
        "    summary_lr.append({\n",
        "        'file': file,\n",
        "        'last_time': last_time,\n",
        "        'last_time_pred': last_time_pred,\n",
        "        'percentage_diff': percentage_diff\n",
        "    })"
      ],
      "metadata": {
        "id": "RtCMC4XYi6QO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for processed files\n",
        "output_folder_path = '/content/content/Rider1_test_NN/'\n",
        "summary_nn = []\n",
        "processed_files = [f for f in os.listdir(output_folder_path) if f.endswith('.csv')]\n",
        "\n",
        "for file in processed_files:\n",
        "    file_path = os.path.join(output_folder_path, file)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Extract the last value of 'Time' and 'Time_pred'\n",
        "    last_time = df['Time'].iloc[-1]\n",
        "    last_time_pred = df['Time_pred'].iloc[-1]\n",
        "\n",
        "    # Calculate percentage difference\n",
        "    percentage_diff = ((last_time_pred - last_time) / last_time) * 100 if last_time != 0 else None\n",
        "\n",
        "    # Append to summary\n",
        "    summary_nn.append({\n",
        "        'file': file,\n",
        "        'last_time': last_time,\n",
        "        'last_time_pred': last_time_pred,\n",
        "        'percentage_diff': percentage_diff\n",
        "    })"
      ],
      "metadata": {
        "id": "L_Q6xesa8UbX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print summary\n",
        "summary_lr_df = pd.DataFrame(summary_lr).sort_values(by=['file'])\n",
        "print(summary_lr_df)\n",
        "print(f\"Absolute percentage difference in LR model: {summary_lr_df['percentage_diff'].abs().mean()}\\n\")\n",
        "\n",
        "summary_nn_df = pd.DataFrame(summary_nn).sort_values(by=['file'])\n",
        "print(summary_nn_df)\n",
        "print(f\"Absolute percentage difference in NN model: {summary_nn_df['percentage_diff'].abs().mean()}\")"
      ],
      "metadata": {
        "id": "WU5ltW-L8RfJ",
        "outputId": "e46e1e47-1058-49e1-85ee-8e321caf2fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          file  last_time  last_time_pred  percentage_diff\n",
            "0  lr_f114.csv       9630     7157.584003       -25.674102\n",
            "6  lr_f123.csv       3791     3709.756866        -2.143053\n",
            "5  lr_f139.csv      11311    11480.384531         1.497520\n",
            "8  lr_f196.csv       6416     6655.971591         3.740206\n",
            "7  lr_f234.csv      19531     9217.082911       -52.807931\n",
            "4  lr_f562.csv       1283      593.353649       -53.752638\n",
            "9  lr_f593.csv      11581     4104.998230       -64.554026\n",
            "1  lr_f660.csv       5839     6407.278490         9.732463\n",
            "3  lr_f673.csv        126       94.968318       -24.628319\n",
            "2   lr_f80.csv       9183     3911.889730       -57.400743\n",
            "Absolute percentage difference in LR model: 29.593100147271805\n",
            "\n",
            "          file  last_time  last_time_pred  percentage_diff\n",
            "0  nn_f114.csv       9630     6426.064130       -33.270362\n",
            "7  nn_f123.csv       3791     3399.608560       -10.324227\n",
            "6  nn_f139.csv      11311    10891.722521        -3.706812\n",
            "5  nn_f196.csv       6416     6453.075144         0.577854\n",
            "4  nn_f234.csv      19531    10382.738269       -46.839700\n",
            "3  nn_f562.csv       1283      488.235368       -61.945801\n",
            "2  nn_f593.csv      11581     3580.466863       -69.083267\n",
            "1  nn_f660.csv       5839     7346.398601        25.816040\n",
            "8  nn_f673.csv        126      117.585498        -6.678176\n",
            "9   nn_f80.csv       9183     5313.767928       -42.134728\n",
            "Absolute percentage difference in NN model: 30.03769678032386\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}